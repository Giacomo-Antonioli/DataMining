{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings & Importing Libraries\r\n",
    "\r\n",
    "INFO about the notebook  ::\r\n",
    "- df_NAME are the raw dataset imported initially\r\n",
    "- df_join is the joined dataset\r\n",
    "- df_temp is the temporary dataset for each kind of operation\r\n",
    "- df_dropped is the dataset without outliers\r\n",
    "- df_new is the final dataset for the Data Understanding task\r\n",
    "- other df_X name will be evaluated\r\n",
    "\r\n",
    "## Attributes global name & type:\r\n",
    "### Geograph relative  -----\r\n",
    "- continent  ::       object\r\n",
    "- country  ::         object\r\n",
    "- region  ::          object\r\n",
    "### Vendor relative  -------\r\n",
    "- vendor  ::          object\r\n",
    "### Ram relative  ----------\r\n",
    "- brand  ::           object\r\n",
    "- ram_model  ::       object\r\n",
    "- memory_type  ::     object\r\n",
    "- id_ram  ::          object\r\n",
    "- clock  ::           object\r\n",
    "- memory_dim  ::      object\r\n",
    "### Price relative  ---------\r\n",
    "- currency  ::        object\r\n",
    "- sales_usd  ::       float64\r\n",
    "- sales_currency  ::  float64\r\n",
    "### Time relative  ----------\r\n",
    "- time_code  ::       datetime64[ns]\r\n",
    "- week  ::            int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--0.0---------------------  SETTINGS -----------------------------------------\r\n",
    "\"\"\"\r\n",
    "Data Settings & Importing Libraries\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import pylab as pl\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math\r\n",
    "import seaborn as sns\r\n",
    "from scipy import stats\r\n",
    "import sys\r\n",
    "import os\r\n",
    "import collections\r\n",
    "#!conda install --yes --prefix {sys.prefix} plotly\r\n",
    "import plotly.io as pio\r\n",
    "from pandas.plotting import scatter_matrix\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "\r\n",
    "#%matplotlib inline \r\n",
    "\r\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\r\n",
    "#plt.rc('figure', figsize=(10, 8))\r\n",
    "#plt.grid(True)\r\n",
    "os.chdir('D:\\\\Dropbox\\\\Scuola\\\\Pisa\\\\Anno2\\\\Data Mining\\\\Esame\\\\Pratica\\\\python\\\\NewDataset')\r\n",
    "dir = os.getcwd()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#   PRE-PROCESS\r\n",
    "df_geo = pd.read_csv(dir + '\\\\Data\\\\geography.csv')\r\n",
    "df_ram = pd.read_csv(dir + '\\\\Data\\\\ram.csv')\r\n",
    "df_sales_ram = pd.read_csv(dir + '\\\\Data\\\\sales_ram.csv')\r\n",
    "df_time = pd.read_csv(dir + '\\\\Data\\\\time.csv')\r\n",
    "df_vendor = pd.read_csv(dir + '\\\\Data\\\\vendor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Attributes and basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset  geography\n",
      "\n",
      "Number of rows:: 75\n",
      "\n",
      "Number of columns:: 6\n",
      "\n",
      "Column Names:: ['Unnamed: 0', 'geo_code', 'continent', 'country', 'region', 'currency']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0    75 non-null int64\n",
      "geo_code      75 non-null int64\n",
      "continent     75 non-null object\n",
      "country       75 non-null object\n",
      "region        75 non-null object\n",
      "currency      75 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.6+ KB\n",
      "\n",
      "        Unnamed: 0  geo_code continent  country                  region  \\\n",
      "count        75.00     75.00        75       75                      75   \n",
      "unique         nan       nan         3       11                      75   \n",
      "top            nan       nan    Europe  Germany  mecklenburg-vorpommern   \n",
      "freq           nan       nan        49       16                       1   \n",
      "mean         38.00     38.00       NaN      NaN                     NaN   \n",
      "std          21.79     21.79       NaN      NaN                     NaN   \n",
      "min           1.00      1.00       NaN      NaN                     NaN   \n",
      "25%          19.50     19.50       NaN      NaN                     NaN   \n",
      "50%          38.00     38.00       NaN      NaN                     NaN   \n",
      "75%          56.50     56.50       NaN      NaN                     NaN   \n",
      "max          75.00     75.00       NaN      NaN                     NaN   \n",
      "\n",
      "       currency  \n",
      "count        75  \n",
      "unique        6  \n",
      "top         EUR  \n",
      "freq         38  \n",
      "mean        NaN  \n",
      "std         NaN  \n",
      "min         NaN  \n",
      "25%         NaN  \n",
      "50%         NaN  \n",
      "75%         NaN  \n",
      "max         NaN  \n",
      "\n",
      "   Unnamed: 0  geo_code continent    country              region currency\n",
      "0           1         1   Oceania  Australia  northern territory      AUD\n",
      "1           2         2   Oceania  Australia          queensland      AUD\n",
      "2           3         3   Oceania  Australia     south australia      AUD\n",
      "3           4         4   Oceania  Australia            tasmania      AUD\n",
      "4           5         5   Oceania  Australia            victoria      AUD\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Dataset  ram\n",
      "\n",
      "Number of rows:: 3705\n",
      "\n",
      "Number of columns:: 6\n",
      "\n",
      "Column Names:: ['ram_code', 'brand', 'name', 'memory', 'memory_type', 'clock']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3705 entries, 0 to 3704\n",
      "Data columns (total 6 columns):\n",
      "ram_code       3705 non-null int64\n",
      "brand          3705 non-null object\n",
      "name           3705 non-null object\n",
      "memory         3705 non-null float64\n",
      "memory_type    3705 non-null object\n",
      "clock          3705 non-null int64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 173.8+ KB\n",
      "\n",
      "        ram_code    brand               name  memory memory_type   clock\n",
      "count    3705.00     3705               3705 3705.00        3705 3705.00\n",
      "unique       nan       54                331     nan           7     nan\n",
      "top          nan  G.SKILL  Corsair Vengeance     nan        DDR3     nan\n",
      "freq         nan      558                113     nan        1830     nan\n",
      "mean     1853.00      NaN                NaN   16.28         NaN 1969.17\n",
      "std      1069.69      NaN                NaN   20.42         NaN  797.26\n",
      "min         1.00      NaN                NaN    0.12         NaN  100.00\n",
      "25%       927.00      NaN                NaN    4.00         NaN 1333.00\n",
      "50%      1853.00      NaN                NaN    8.00         NaN 1866.00\n",
      "75%      2779.00      NaN                NaN   16.00         NaN 2400.00\n",
      "max      3705.00      NaN                NaN  256.00         NaN 4600.00\n",
      "\n",
      "   ram_code  brand   name  memory memory_type  clock\n",
      "0         2  ADATA  Adata    1.00         DDR    333\n",
      "1         1  ADATA  Adata    0.50         DDR    400\n",
      "2         3  ADATA  Adata    1.00         DDR    400\n",
      "3         4  ADATA  Adata    2.00         DDR    400\n",
      "4         5  ADATA  Adata    1.00        DDR2    667\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Dataset  sales_ram\n",
      "\n",
      "Number of rows:: 3412331\n",
      "\n",
      "Number of columns:: 8\n",
      "\n",
      "Column Names:: ['Unnamed: 0', 'Id', 'ram_code', 'time_code', 'geo_code', 'vendor_code', 'sales_uds', 'sales_currency']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3412331 entries, 0 to 3412330\n",
      "Data columns (total 8 columns):\n",
      "Unnamed: 0        int64\n",
      "Id                int64\n",
      "ram_code          float64\n",
      "time_code         int64\n",
      "geo_code          int64\n",
      "vendor_code       int64\n",
      "sales_uds         float64\n",
      "sales_currency    float64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 208.3 MB\n",
      "\n",
      "       Unnamed: 0         Id   ram_code   time_code   geo_code  vendor_code  \\\n",
      "count  3412331.00 3412331.00 3412331.00  3412331.00 3412331.00   3412331.00   \n",
      "mean   4308512.00    5257.61    1539.61 20161656.42      32.93        39.49   \n",
      "std     985055.26     853.69     853.69    13093.20      18.97        14.16   \n",
      "min    2602347.00    3719.00       1.00 20130322.00       1.00         1.00   \n",
      "25%    3455429.50    4522.00     804.00 20151123.00      20.00        32.00   \n",
      "50%    4308512.00    5141.00    1423.00 20161110.00      26.00        32.00   \n",
      "75%    5161594.50    5957.00    2239.00 20170811.00      32.00        45.00   \n",
      "max    6014677.00    7422.00    3704.00 20180412.00      75.00        81.00   \n",
      "\n",
      "        sales_uds  sales_currency  \n",
      "count  3412331.00      3412331.00  \n",
      "mean       181.43          159.07  \n",
      "std       8536.83         5426.38  \n",
      "min          0.71            0.50  \n",
      "25%         48.58           42.02  \n",
      "50%         99.07           87.60  \n",
      "75%        205.87          182.90  \n",
      "max   15741338.31      9999999.99  \n",
      "\n",
      "   Unnamed: 0    Id  ram_code  time_code  geo_code  vendor_code  sales_uds  \\\n",
      "0     2602347  3719      1.00   20130322        25           32      13.75   \n",
      "1     2602348  3719      1.00   20130323        18           32      13.83   \n",
      "2     2602349  3719      1.00   20130326        28           32      13.69   \n",
      "3     2602350  3719      1.00   20130327        25           32      13.69   \n",
      "4     2602351  3719      1.00   20130328        27           32      13.61   \n",
      "\n",
      "   sales_currency  \n",
      "0           10.65  \n",
      "1           10.65  \n",
      "2           10.65  \n",
      "3           10.65  \n",
      "4           10.65  \n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Dataset  time\n",
      "\n",
      "Number of rows:: 1840\n",
      "\n",
      "Number of columns:: 6\n",
      "\n",
      "Column Names:: ['Unnamed: 0', 'time_code', 'year', 'month', 'day', 'week']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1840 entries, 0 to 1839\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0    1840 non-null int64\n",
      "time_code     1840 non-null int64\n",
      "year          1840 non-null int64\n",
      "month         1840 non-null int64\n",
      "day           1840 non-null int64\n",
      "week          1840 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 86.4 KB\n",
      "\n",
      "       Unnamed: 0   time_code    year   month     day    week\n",
      "count     1840.00     1840.00 1840.00 1840.00 1840.00 1840.00\n",
      "mean       923.58 20153241.55 2015.26    6.50   15.73   26.92\n",
      "std        533.56    14889.19    1.50    3.44    8.81   15.04\n",
      "min          0.00 20130322.00 2013.00    1.00    1.00    1.00\n",
      "25%        459.75 20140626.75 2014.00    4.00    8.00   14.00\n",
      "50%        925.50 20151005.50 2015.00    6.00   16.00   27.00\n",
      "75%       1385.25 20170107.25 2017.00    9.25   23.00   40.00\n",
      "max       1845.00 20180412.00 2018.00   12.00   31.00   53.00\n",
      "\n",
      "   Unnamed: 0  time_code  year  month  day  week\n",
      "0           0   20130322  2013      3   22    12\n",
      "1           1   20130323  2013      3   23    12\n",
      "2           2   20130326  2013      3   26    13\n",
      "3           3   20130327  2013      3   27    13\n",
      "4           4   20130328  2013      3   28    13\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "Dataset  vendor\n",
      "\n",
      "Number of rows:: 78\n",
      "\n",
      "Number of columns:: 3\n",
      "\n",
      "Column Names:: ['Unnamed: 0', 'vendor_code', 'name']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78 entries, 0 to 77\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0     78 non-null int64\n",
      "vendor_code    78 non-null int64\n",
      "name           78 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.0+ KB\n",
      "\n",
      "        Unnamed: 0  vendor_code                name\n",
      "count        78.00        78.00                  78\n",
      "unique         nan          nan                  78\n",
      "top            nan          nan  Overclockers.co.uk\n",
      "freq           nan          nan                   1\n",
      "mean         40.56        41.56                 NaN\n",
      "std          23.46        23.46                 NaN\n",
      "min           0.00         1.00                 NaN\n",
      "25%          21.25        22.25                 NaN\n",
      "50%          40.50        41.50                 NaN\n",
      "75%          60.75        61.75                 NaN\n",
      "max          80.00        81.00                 NaN\n",
      "\n",
      "   Unnamed: 0  vendor_code                  name\n",
      "0           0            1  1stWave Technologies\n",
      "1           1            2               Adorama\n",
      "2           2            3             Alternate\n",
      "3           3            4      Alternate Italia\n",
      "4           4            5                  Alza\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for set in [\"geography\", \"ram\", \"sales_ram\", \"time\", \"vendor\"]:\r\n",
    "    df = pd.read_csv(dir + '\\\\Data\\\\' + set + '.csv')\r\n",
    "    print(\"\\n\\nDataset \", set)\r\n",
    "    print(\"\\nNumber of rows::\",df.shape[0])   \r\n",
    "    print(\"\\nNumber of columns::\",df.shape[1] )   \r\n",
    "    print(\"\\nColumn Names::\",df.columns.values.tolist())\r\n",
    "    print()\r\n",
    "    df.info()\r\n",
    "    print()\r\n",
    "    #print(df.dtypes)\r\n",
    "    print(df.describe(include='all'))\r\n",
    "    print()\r\n",
    "    print(df.head())\r\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conversion of some attributes before the join operation\n",
    "df_sales_ram['ram_code'] = df_sales_ram['ram_code'].astype(int)\n",
    "df_sales_ram['vendor_code'] = df_sales_ram['vendor_code'].astype(int)\n",
    "df_sales_ram['geo_code'] = df_sales_ram['geo_code'].astype(int)\n",
    "df_sales_ram['Id'] = df_sales_ram['Id'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary operation for integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some renaming\r\n",
    "df_vendor = df_vendor.rename(columns={\"name\": \"vendor\"})\r\n",
    "df_ram = df_ram.rename(columns={\"name\": \"ram_model\"})\r\n",
    "df_ram = df_ram.rename(columns={\"memory\": \"memory_dim\"})\r\n",
    "df_sales_ram = df_sales_ram.rename(columns={\"Id\": \"id_ram\"})\r\n",
    "df_sales_ram = df_sales_ram.rename(columns={\"sales_uds\": \"sales_usd\"})\r\n",
    "\r\n",
    "# Some dropping  \r\n",
    "df_vendor = df_vendor.drop(columns=['Unnamed: 0'])\r\n",
    "df_time = df_time.drop(columns=['Unnamed: 0'])\r\n",
    "df_geo = df_geo.drop(columns=['Unnamed: 0'])\r\n",
    "df_sales_ram = df_sales_ram.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join operations\r\n",
    "df_join = df_sales_ram.join(df_ram.set_index('ram_code'), on='ram_code')\r\n",
    "df_join = df_join.join(df_vendor.set_index('vendor_code'), on='vendor_code')\r\n",
    "df_join = df_join.join(df_geo.set_index('geo_code'), on='geo_code')\r\n",
    "df_join = df_join.join(df_time.set_index('time_code'), on='time_code')\r\n",
    "\r\n",
    "\r\n",
    "# Post operations\r\n",
    "df_join['time_code'] = pd.to_datetime(df_join['time_code'], format='%Y%m%d')\r\n",
    "#-----Reduction of attributes, Some removal\r\n",
    "df_join.drop(['geo_code', 'ram_code', 'year', 'day', 'vendor_code'], inplace=True, axis=1)\r\n",
    "df_join['clock'] = df_join['clock'].astype(object)\r\n",
    "df_join['memory_dim'] = df_join['memory_dim'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4872\n",
      "46848\n"
     ]
    }
   ],
   "source": [
    "df_temp = df_join[(df_join.time_code.dt.year == 2013) & (df_join.time_code.dt.month == 3)]\r\n",
    "print(len(df_temp))\r\n",
    "df_join.drop(df_temp.index, inplace=True)\r\n",
    "\r\n",
    "df_temp = df_join[(df_join.time_code.dt.year == 2018) & (df_join.time_code.dt.month == 4)]\r\n",
    "print(len(df_temp))\r\n",
    "df_join.drop(df_temp.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3360611 entries, 8 to 3412330\n",
      "Data columns (total 16 columns):\n",
      "id_ram            object\n",
      "time_code         datetime64[ns]\n",
      "sales_usd         float64\n",
      "sales_currency    float64\n",
      "brand             object\n",
      "ram_model         object\n",
      "memory_dim        object\n",
      "memory_type       object\n",
      "clock             object\n",
      "vendor            object\n",
      "continent         object\n",
      "country           object\n",
      "region            object\n",
      "currency          object\n",
      "month             int64\n",
      "week              int64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(11)\n",
      "memory usage: 435.9+ MB\n",
      "---------------------------------------------------------------\n",
      "           id_ram            time_code   sales_usd  sales_currency    brand  \\\n",
      "count  3360611.00              3360611  3360611.00      3360611.00  3360611   \n",
      "unique    3109.00                 1820         nan             nan       48   \n",
      "top       5764.00  2016-04-11 00:00:00         nan             nan  G.SKILL   \n",
      "freq      8840.00                 5560         nan             nan   821334   \n",
      "first         nan  2013-04-01 00:00:00         nan             nan      NaN   \n",
      "last          nan  2018-03-31 00:00:00         nan             nan      NaN   \n",
      "mean          nan                  NaN      180.43          158.18      NaN   \n",
      "std           nan                  NaN     8602.19         5467.87      NaN   \n",
      "min           nan                  NaN        0.71            0.50      NaN   \n",
      "25%           nan                  NaN       48.35           41.90      NaN   \n",
      "50%           nan                  NaN       98.45           86.99      NaN   \n",
      "75%           nan                  NaN      204.49          181.62      NaN   \n",
      "max           nan                  NaN 15741338.31      9999999.99      NaN   \n",
      "\n",
      "                ram_model  memory_dim memory_type      clock  \\\n",
      "count             3360611  3360611.00     3360611 3360611.00   \n",
      "unique                280       18.00           7      43.00   \n",
      "top     Corsair Vengeance        8.00        DDR3    1600.00   \n",
      "freq               261625   816507.00     1444497  690350.00   \n",
      "first                 NaN         nan         NaN        nan   \n",
      "last                  NaN         nan         NaN        nan   \n",
      "mean                  NaN         nan         NaN        nan   \n",
      "std                   NaN         nan         NaN        nan   \n",
      "min                   NaN         nan         NaN        nan   \n",
      "25%                   NaN         nan         NaN        nan   \n",
      "50%                   NaN         nan         NaN        nan   \n",
      "75%                   NaN         nan         NaN        nan   \n",
      "max                   NaN         nan         NaN        nan   \n",
      "\n",
      "                  vendor continent  country         region currency  \\\n",
      "count            3360611   3360611  3360611        3360611  3360611   \n",
      "unique                78         3       11             75        6   \n",
      "top     geizhals_unknown    Europe  Germany  saxony-anhalt      EUR   \n",
      "freq             2021461   2852027  2160331         142416  2344699   \n",
      "first                NaN       NaN      NaN            NaN      NaN   \n",
      "last                 NaN       NaN      NaN            NaN      NaN   \n",
      "mean                 NaN       NaN      NaN            NaN      NaN   \n",
      "std                  NaN       NaN      NaN            NaN      NaN   \n",
      "min                  NaN       NaN      NaN            NaN      NaN   \n",
      "25%                  NaN       NaN      NaN            NaN      NaN   \n",
      "50%                  NaN       NaN      NaN            NaN      NaN   \n",
      "75%                  NaN       NaN      NaN            NaN      NaN   \n",
      "max                  NaN       NaN      NaN            NaN      NaN   \n",
      "\n",
      "            month       week  \n",
      "count  3360611.00 3360611.00  \n",
      "unique        nan        nan  \n",
      "top           nan        nan  \n",
      "freq          nan        nan  \n",
      "first         nan        nan  \n",
      "last          nan        nan  \n",
      "mean         6.54      27.23  \n",
      "std          3.49      15.32  \n",
      "min          1.00       1.00  \n",
      "25%          3.00      13.00  \n",
      "50%          7.00      27.00  \n",
      "75%         10.00      41.00  \n",
      "max         12.00      53.00  \n",
      "---------------------------------------------------------------\n",
      "   id_ram  time_code  sales_usd  sales_currency  brand ram_model memory_dim  \\\n",
      "8    3719 2013-04-01      13.66           10.65  ADATA     Adata       0.50   \n",
      "9    3719 2013-04-02      13.69           10.65  ADATA     Adata       0.50   \n",
      "10   3719 2013-04-03      13.67           10.65  ADATA     Adata       0.50   \n",
      "11   3719 2013-04-04      13.68           10.65  ADATA     Adata       0.50   \n",
      "12   3719 2013-04-05      13.72           10.65  ADATA     Adata       0.50   \n",
      "\n",
      "   memory_type clock            vendor continent  country  \\\n",
      "8          DDR   400  geizhals_unknown    Europe  Germany   \n",
      "9          DDR   400  geizhals_unknown    Europe  Germany   \n",
      "10         DDR   400  geizhals_unknown    Europe  Germany   \n",
      "11         DDR   400  geizhals_unknown    Europe  Germany   \n",
      "12         DDR   400  geizhals_unknown    Europe  Germany   \n",
      "\n",
      "                    region currency  month  week  \n",
      "8                  bavaria      EUR      4    14  \n",
      "9            saxony-anhalt      EUR      4    14  \n",
      "10  north rhine-westphalla      EUR      4    14  \n",
      "11                 bavaria      EUR      4    14  \n",
      "12      schleswig-holstein      EUR      4    14  \n",
      "---------------------------------------------------------------\n",
      "\n",
      "Distinct values in clock : \t [400 333 667 800 1333 1600 2400 2666 3000 3200 3300 3333 2133 2800 2000\n",
      " 1866 3600 2600 3100 2933 533 1066 266 1800 3466 3733 3866 4000 3400 3666\n",
      " 4133 3800 4200 4266 4333 4400 4500 4600 133 1000 750 2250 100]\n",
      "\n",
      "Distinct values in memory_dim : \t [0.5 1.0 2.0 4.0 8.0 16.0 32.0 64.0 3.0 6.0 12.0 24.0 128.0 0.25 48.0 96.0\n",
      " 256.0 0.125]\n",
      "\n",
      "Distinct values in id_ram : \t [3719 3720 3721 ... 7419 7421 7422]\n",
      "\n",
      "Distinct values in time_code : \t ['2013-04-01T00:00:00.000000000' '2013-04-02T00:00:00.000000000'\n",
      " '2013-04-03T00:00:00.000000000' ... '2017-10-13T00:00:00.000000000'\n",
      " '2017-08-22T00:00:00.000000000' '2017-05-19T00:00:00.000000000']\n",
      "\n",
      "Distinct values in brand : \t ['ADATA' 'AENEON' 'AFOX' 'AMD' 'APACER' 'AVEXIR' 'BUFFALO' 'COMPUSTOCX'\n",
      " 'CORSAIR' 'CRUCIAL' 'DANE-ELEC' 'EDGE' 'ELIXIR' 'EXTREMEMORY' 'G.SKILL'\n",
      " 'GALAX/KFA2' 'GEIL' 'GOODRAM' 'HP' 'HYNIX' 'IBM' 'INTEGRAL' 'INTENSO'\n",
      " 'KFA&SUP2' 'KINGMAX' 'KINGSTON' 'KLEVV' 'LEXAR' 'MDT' 'MICRON' 'MUSHKIN'\n",
      " 'MUSTANG' 'NILOX' 'OCZ' 'PANRAM' 'PAREEMA' 'PATRIOT' 'PNY' 'SAMSUNG'\n",
      " 'SILICON' 'SK' 'SUPER' 'TEAM GROUP' 'TOSHIBA' 'TRANSCEND' 'V7'\n",
      " 'VISIONTEK' 'WINTEC']\n",
      "\n",
      "Distinct values in ram_model : \t ['Adata' 'Adata Performance Value' 'Adata Premier' 'Adata Supreme'\n",
      " 'Adata Value' 'Adata Xpg Dazzle' 'Adata Xpg Flame' 'Adata Xpg Gaming'\n",
      " 'Adata Xpg Gammix D10' 'Adata Xpg Spectrix D40' 'Adata Xpg V1.0'\n",
      " 'Adata Xpg V2' 'Adata Xpg V3' 'Adata Xpg Z1' 'Aeneon' 'Afox' 'Amd'\n",
      " 'Amd Performance Edition' 'Amd R5 Entertainment' 'Amd R7 Performance'\n",
      " 'Amd R9 2400' 'Amd R9 Gamer' 'Apacer' 'Apacer Armor'\n",
      " 'Apacer Black Panther' 'Apacer Blade' 'Apacer Blade Fire'\n",
      " 'Apacer Commando' 'Apacer Nox' 'Apacer Panther' 'Apacer Thunderbird Blue'\n",
      " 'Avexir' 'Avexir Blitz' 'Avexir Blitz 1.1' 'Avexir Budget' 'Avexir Core'\n",
      " 'Avexir Green' 'Avexir Mpower' 'Avexir Notebook' 'Avexir Raiden'\n",
      " 'Avexir Rog' 'Buffalo' 'Compustocx' 'Corsair' 'Corsair Dominator'\n",
      " 'Corsair Fb' 'Corsair Mac Memory' 'Corsair Platinum' 'Corsair Server'\n",
      " 'Corsair Value Select' 'Corsair Vengeance' 'Corsair Xms' 'Corsair Xms2'\n",
      " 'Corsair Xms3' 'Crucial' 'Crucial Ballistix' 'Crucial Ballistix Elite'\n",
      " 'Crucial Ballistix Smart Tracer' 'Crucial Ballistix Sport'\n",
      " 'Crucial Ballistix Tactical' 'Crucial Fb' 'Crucial Lr'\n",
      " 'Crucial Memory For Mac' 'Crucial Server' 'Crucial Vlp' 'Dane-Elec Value'\n",
      " 'Edge Tech' 'Elixir' 'Extrememory' 'G.Skill' 'G.Skill Aegis'\n",
      " 'G.Skill Ares' 'G.Skill Eco' 'G.Skill Flare X' 'G.Skill For Mac'\n",
      " 'G.Skill Fortis' 'G.Skill Hk' 'G.Skill Mq' 'G.Skill Nq' 'G.Skill Ns'\n",
      " 'G.Skill Nt' 'G.Skill Performance' 'G.Skill Pi' 'G.Skill Pk' 'G.Skill Pq'\n",
      " 'G.Skill Ripjaws' 'G.Skill Ripjaws 4' 'G.Skill Ripjaws V'\n",
      " 'G.Skill Ripjaws X' 'G.Skill Ripjaws Z' 'G.Skill Sa' 'G.Skill Sk'\n",
      " 'G.Skill Sl' 'G.Skill Sniper' 'G.Skill Sniper Gaming' 'G.Skill Sniper X'\n",
      " 'G.Skill Sq' 'G.Skill Trident' 'G.Skill Trident X' 'G.Skill Trident Z'\n",
      " 'G.Skill Value' 'G.Skill Value Ns' 'G.Skill Value Nt' 'Galax Hof' 'Geil'\n",
      " 'Geil Dragon' 'Geil Enhance Corsa' 'Geil Evo Corsa' 'Geil Evo Forza'\n",
      " 'Geil Evo Leggera' 'Geil Evo Potenza' 'Geil Evo Spear' 'Geil Evo Two'\n",
      " 'Geil Evo Veloce' 'Geil Evo X' 'Geil Green' 'Geil Pristine'\n",
      " 'Geil Pristine Amd Edition' 'Geil Super Luce' 'Geil Ultra' 'Geil Value'\n",
      " 'Geil Value Plus' 'Goodram' 'Goodram Irdm' 'Goodram Play' 'Hp' 'Hynix'\n",
      " 'Hynix Server' 'Ibm' 'Integral' 'Intenso' 'Kingmax' 'Kingston'\n",
      " 'Kingston Beast' 'Kingston Black' 'Kingston Blu' 'Kingston Blu Red'\n",
      " 'Kingston Hyperx' 'Kingston Hyperx Fury' 'Kingston Hyperx Impact'\n",
      " 'Kingston Hyperx Predator' 'Kingston Hyperx Savage' 'Kingston Lovo'\n",
      " 'Kingston Lv Xmp 10Th Anniversary' 'Kingston Server Premier'\n",
      " 'Kingston Value' 'Kingston Valueram' 'Kingston Valueram Bulk'\n",
      " 'Kingston Valueram Elpida' 'Kingston Valueram Fb-'\n",
      " 'Kingston Valueram Hynix' 'Kingston Valueram Hynix A-Die'\n",
      " 'Kingston Valueram Hynix B-Die' 'Kingston Valueram Intel'\n",
      " 'Kingston Valueram Intel Lr' 'Kingston Valueram Lr'\n",
      " 'Kingston Valueram Server Premier' 'Kingston Valueram Server Premier Vlp'\n",
      " 'Kingston Valueram Ts' 'Kingston Valueram Vlp'\n",
      " 'Kingston Xmp 10Th Anniversary' 'Kingston Xmp Blu Red' 'Klevv Cras'\n",
      " 'Klevv Cras Red' 'Klevv Cras Red Led' 'Klevv Fit'\n",
      " 'Klevv Fit Faker Edition' 'Klevv Genuine' 'Klevv Genuine Led' 'Klevv Neo'\n",
      " 'Klevv Urbane' 'Lexar' 'Mdt' 'Micron' 'Micron Server' 'Mushkin'\n",
      " 'Mushkin Blackline' 'Mushkin Blackline Frostbyte'\n",
      " 'Mushkin Blackline Frostbyte G3' 'Mushkin Blackline Ridgeback'\n",
      " 'Mushkin Eco2' 'Mushkin Enhanced Apple'\n",
      " 'Mushkin Enhanced Blackline Frostbyte'\n",
      " 'Mushkin Enhanced Blackline Frostbyte G3'\n",
      " 'Mushkin Enhanced Blackline Ridgeback'\n",
      " 'Mushkin Enhanced Blackline Ridgeback G2' 'Mushkin Enhanced Essentials'\n",
      " 'Mushkin Enhanced Fb-' 'Mushkin Enhanced Proline'\n",
      " 'Mushkin Enhanced Radioactive' 'Mushkin Enhanced Redline'\n",
      " 'Mushkin Enhanced Redline Frostbyte'\n",
      " 'Mushkin Enhanced Redline Frostbyte G3'\n",
      " 'Mushkin Enhanced Redline Ridgeback'\n",
      " 'Mushkin Enhanced Redline Ridgeback G2' 'Mushkin Enhanced Silverline'\n",
      " 'Mushkin Enhanced Silverline Frostbyte'\n",
      " 'Mushkin Enhanced Silverline Stiletto'\n",
      " 'Mushkin Enhanced Stealth Stiletto' 'Mushkin Essentials' 'Mushkin Iram'\n",
      " 'Mushkin Proline' 'Mushkin Radioactive' 'Mushkin Radioactive Frostbyte'\n",
      " 'Mushkin Redline' 'Mushkin Redline Frostbyte'\n",
      " 'Mushkin Redline Frostbyte G2' 'Mushkin Redline Frostbyte G3'\n",
      " 'Mushkin Redline Ridgeback G2' 'Mushkin Silverline'\n",
      " 'Mushkin Silverline Stiletto' 'Mushkin Sp' 'Mushkin Stealth'\n",
      " 'Mushkin Stealth Stiletto' 'Mustang' 'Mustang Black Line'\n",
      " 'Mustang Premium Line' 'Mustang Premiumline' 'Nilox' 'Ocz'\n",
      " 'Ocz Blade St Low-Voltage' 'Ocz Gold' 'Ocz Gold Gx Xtc'\n",
      " 'Ocz Gold Low-Voltage Intel Edition' 'Ocz Mac' 'Ocz Obsidian Xtc'\n",
      " 'Ocz Platinum' 'Ocz Reaper Hpc R2' 'Ocz Value' 'Ocz Value Pro' 'Panram'\n",
      " 'Panram Light Sword Red Led' 'Panram Memory' 'Panram Ninja'\n",
      " 'Panram Ninja-V' 'Panram Ninja-V White' 'Panram Performance Blue'\n",
      " 'Panram Value' 'Pareema' 'Patriot' 'Patriot Extreme Performance'\n",
      " 'Patriot G2' 'Patriot Gamer 2' 'Patriot Intel Extreme Master, Limited Ed'\n",
      " 'Patriot Mac' 'Patriot Signature' 'Patriot Viper' 'Patriot Viper 3'\n",
      " 'Patriot Viper 4' 'Patriot Viper Elite' 'Pny' 'Pny Anarchy'\n",
      " 'Pny Anarchy X' 'Pny Nhs' 'Pny Optima' 'Pny Performance' 'Pny Premium'\n",
      " 'Pny Xlr8' 'Samsung' 'Samsung Green' 'Samsung Lr' 'Samsung Original'\n",
      " 'Samsung Server' 'Silicon Power' 'Sk Hynix' 'Super Talent' 'Team Group'\n",
      " 'Team Group Dark' 'Team Group Delta' 'Team Group Elite'\n",
      " 'Team Group Night Hawk' 'Team Group Value' 'Team Group Vulcan'\n",
      " 'Team Group Xtreem' 'Team Group Zeus' 'Toshiba' 'Transcend' 'V7'\n",
      " 'Visiontek' 'Wintec']\n",
      "\n",
      "Distinct values in memory_type : \t ['DDR' 'DDR2' 'DDR3' 'DDR4' 'DDR3L' 'SDR' 'DDR3U']\n",
      "\n",
      "Distinct values in vendor : \t ['geizhals_unknown' 'pricespy_unknown' 'Newegg Marketplace'\n",
      " 'More Computers' 'Newegg Canada' 'Newegg' 'Novatech' 'Custompcparts'\n",
      " 'PC-Canada' 'SmartTeck.co.uk' 'Vuugo' 'Alza' 'Newegg Canada Marketplace'\n",
      " 'Newegg Business' 'OutletPC' 'shopRBC' 'Mindfactory' 'Alternate'\n",
      " 'Alternate Italia' 'Ascent Technology' 'Adorama' 'Aquila Technology'\n",
      " 'Paradigm PCs' 'PB Technologies' 'Mighty Ape' 'Dell' 'Memory Express'\n",
      " 'DTC Systems' 'Caseking' \"Mike's Computer Shop\" 'Newegg Australia'\n",
      " 'Scorptec' 'Mwave Australia' 'Overclockers.co.uk' 'ARLT' 'SuperBiiz'\n",
      " 'IJK' 'Ebuyer' 'Centre Com' 'B H' 'PC Componentes' 'Skycomp Technology'\n",
      " 'Directron' 'Umart' 'PCM' 'BT Shop' 'Corsair' 'LDLC' 'JW Computers'\n",
      " 'Aria PC' 'Scan.co.uk' 'Bytes At Work' 'Corsair DE' 'Corsair UK'\n",
      " 'Laptops Direct' 'PLE Computers' 'PC World Business'\n",
      " 'Dell Small Business' 'Shopping Express' 'Computer Lounge' 'PCCaseGear'\n",
      " 'PC World' 'Komplett' 'Storm Computers' 'Kogan' 'Best Buy' 'Kustom PCs'\n",
      " '1stWave Technologies' 'Box Limited' 'AX86 Gaming Systems' 'PC Force'\n",
      " 'AWD-IT' 'Electronicamente' 'Playtech' 'Monoprice' 'RamCity' 'YoYoTech'\n",
      " 'Senetic']\n",
      "\n",
      "Distinct values in continent : \t ['Europe' 'Oceania' 'America']\n",
      "\n",
      "Distinct values in country : \t ['Germany' 'Spain' 'United Kingdom' 'Australia' 'United States of America'\n",
      " 'Canada' 'Italy' 'Ireland' 'France' 'New Zeland' 'Belgium']\n",
      "\n",
      "Distinct values in region : \t ['bavaria' 'saxony-anhalt' 'north rhine-westphalla' 'schleswig-holstein'\n",
      " 'bremen' 'saxony' 'thuringia' 'berlin' 'brandenburg' 'hamburg'\n",
      " 'rhineland-palatinate' 'analucia' 'mecklenburg-vorpommern' 'lower saxony'\n",
      " 'saarland' 'hessen' 'london' 'scotland' 'south east england' 'queensland'\n",
      " 'north west england' 'west midlands' 'wales' 'north east england'\n",
      " 'east midlands' 'south west england' 'yorkshire' 'mid-atalntic'\n",
      " 'mid-west usa' 'north-east usa' 'south west usa' 'south-east usa'\n",
      " 'north west usa' 'west usa' 'baden-wuttemberg' 'ontario' 'the north'\n",
      " 'quebec' 'british columbia' 'prairie provinces' 'center italy' 'leinster'\n",
      " 'ulster' 'munster' 'galicia' 'asturleon' 'le midi france' 'connaught'\n",
      " 'castilla' 'southwest france' 'north east france' 'aragon' 'north italy'\n",
      " 'north west france' 'north island-central east' 'vascongadas'\n",
      " 'south italy' 'upland france' 'north island-southern'\n",
      " 'south island-southern' 'south island-central'\n",
      " 'north island-central west' 'northern island-northern'\n",
      " 'south island northern' 'east england' 'northern territory'\n",
      " 'western australia' 'victoria' 'brussels' 'south australia' 'tasmania'\n",
      " 'heart of france' 'atlantic provinces' 'wallonia' 'flanders']\n",
      "\n",
      "Distinct values in currency : \t ['EUR' 'GBP' 'AUD' 'USD' 'CAD' 'NZD']\n"
     ]
    }
   ],
   "source": [
    "df_join.info()\r\n",
    "print(\"---------------------------------------------------------------\")\r\n",
    "print(df_join.describe(include='all'))\r\n",
    "print(\"---------------------------------------------------------------\")\r\n",
    "print(df_join.head())\r\n",
    "print(\"---------------------------------------------------------------\")\r\n",
    "\r\n",
    "#   Attributes split by type - RIMUOVERE week & sales_uds\r\n",
    "num_float = ['sales_usd', 'sales_currency']\r\n",
    "cat = [\"clock\", \"memory_dim\", 'id_ram', 'time_code', 'brand', 'ram_model', 'memory_type', 'vendor', 'continent', 'country', 'region', \"currency\"]\r\n",
    "\r\n",
    "#   per vedere i valori distinti - USARE ATTRIBUTI CATEGORICI\r\n",
    "for col in cat: \r\n",
    "    print(\"\\nDistinct values in \" + col + \" : \\t\", df_join[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_join.sort_values( by=\"sales_usd\", ascending=False)\r\n",
    "print(df_temp.describe())\r\n",
    "print()\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "#ax.set_title('\\nOutliers of ' +col+ ' in the Dataset')\r\n",
    "ax.boxplot(df_temp[\"sales_usd\"])\r\n",
    "\r\n",
    "print(\"---------------------------------------------------------------\")\r\n",
    "\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"sales_usd\"] > 5000]\r\n",
    "print(df_temp1.head(50))\r\n",
    "print()\r\n",
    "\r\n",
    "print(df_temp[(df_temp[\"id_ram\"] == 3753) & (df_temp[\"brand\"] == \"ADATA\") & (df_temp[\"memory_dim\"] == 4.00) & (df_temp[\"memory_type\"] == \"DDR3\") & (df_temp[\"clock\"] == 1600) & (df_temp[\"time_code\"].dt.year > 2015) ])\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join[df_join[\"week\"] == 53] #oltre il 50%\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join[[\"week\", \"time_code\"]]\r\n",
    "df_temp = df_temp[df_temp[\"week\"] == 52]\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "# sembra essere normale la ripartizione delle settimane, il possibile intoppo credo possa essere\r\n",
    "    # tra la 1a e la 2a settimana\r\n",
    "    # nella repository d'esempio noto da 1 a 52\r\n",
    "    # non centrano anni bisestili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join[[\"time_code\", \"week\"]][(df_join[\"time_code\"].dt.week == 1) & (df_join[\"week\"] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join[[\"time_code\", \"week\"]][df_join[\"time_code\"].dt.week == 53]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- devo rilavorare sales_currency e usd per ottenere una migliore distribuzione\r\n",
    "- settimana ha il valore 53: ci sono 47030 valori con settimana 53\r\n",
    "    - voglio relazionare timecode e week\r\n",
    "        - HO NOTATO CHE week "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates/Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\r\n",
    "print(\"\\nColumns with Missing Values::\",df_join.columns[df_join.isnull().any()].tolist())\r\n",
    "print(df_join.isnull().sum())   #0\r\n",
    "\r\n",
    "# duplicates\r\n",
    "print(\"\\nNumber of duplicates is::\")\r\n",
    "print(df_join.duplicated().sum())   #0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and TIME_CODE Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"time_code\"\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].nunique()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\"\"\"df_temp = df_join.groupby(y)[x].nunique().reset_index(name=\"new_\" + x)\r\n",
    "#df_temp = df_temp[\"new_\" + x].value_counts()\r\n",
    "#print(df_temp[df_temp.groupby(y)[y] == 1])\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "#print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "#print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "#print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "#print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un unico time_code (giorno) associato con 6 id_ram\r\n",
    "- c'è un unico id_ram associato a 1840 giorni diversi\r\n",
    "- il giorno che ho venduto meno schede diverse\r\n",
    "- il giorno che ho venduto più schede diverse\r\n",
    "- il giorno che ho venduto meno schede non_uniche (171) (2017-08-22)\r\n",
    "- il giorno che ho venduto più schede non_uniche (8052) (2018-04-11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and SALES_USD Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "##------  continent: quale altro attributo è presente di più\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"sales_usd\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 61 id_ram con un unico prezzo (OK)\r\n",
    "- c'è un id_ram con 8581 prezzi diversi (OK)\r\n",
    "- c'è un prezzo associato a 271 id_ram diversi (il prezzo più presente tra tutti) (99.99)\r\n",
    "- il prezzo più presente nel dataset potrebbe essere 89.99USD (CHECK ultimo print)\r\n",
    "- ci sono 2759825 prezzi diversi associati ad un unica ram (la ram con più variazioni di prezzi)(stessa valuta) (OK)\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and SALES_CURRENCY Attributes\t- NV,\r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"sales_currency\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x )\r\n",
    "print(df_temp)\r\n",
    "print()\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].nunique()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "con groupby\r\n",
    "- ci sono 142 id_ram con associati un prezzo unico (OK)\r\n",
    "- c'è un id_ram con 6244 prezzi deversi (OK) (id_ram == 4377, Corsair Vengance 16Gb DDR4)\r\n",
    "\r\n",
    "- 259545 prezzi unici (in totale) \r\n",
    "- 231088 prezzi totali\r\n",
    "- il prezzo (totalmente) più presente (438 volte) è 79.99 (con valuta) \r\n",
    "- il 18.79 (non per forza usd) è presente 3156 volte su id_ram non uniche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and BRAND Attributes\t\t- U&V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"id_ram\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"id_ram\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- verificato che ogni id_ram può avere un solo brand associato\r\n",
    "\r\n",
    "----------------------------------------------------------------\r\n",
    "- 8 brand vendono un unica versione di un unico prodotto (OK)\r\n",
    "- c'è un brand (G.SKILL) che vende 517 prodotti unici, ma totali 833668 (max) (OK)\r\n",
    "- il brand che ha venduto meno è DANE-ELEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and RAM_MODEL Attributes\t\t- U&V,\r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"id_ram\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].nunique()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"id_ram\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- verificato che ogni id_ram può avere un solo nome associato\r\n",
    "    discorso valido anche per le dimensioni di memoria, le tipologie di memoria, freq. di clock\r\n",
    "        uniche per ogni id_ram\r\n",
    "\r\n",
    "\r\n",
    "----------------------------------------------------------------\r\n",
    "- ci sono 51 modelli di ram (nomi diversi) venduti in unica versione (freq.,mem.,tech.,ecc.) (OK)\r\n",
    "- c'è un modello (Corsair Vengance) presente con 113 versioni differenti (freq.,mem.,tech.,ecc.) non uniche (OK)\r\n",
    "- il modello che è stato venduto un unica volta è il Kingston Lv Xmp 10Th Anniversary\r\n",
    "    perchè sembra essere un edizione speciale\r\n",
    "- il modello con più vendite è il Corsair Vengeance  (266917)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and VENDOR Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 1306 id_ram diversi con associati un unico venditore (OK)\r\n",
    "    - il venditore che ha acquistato più ram diverse, \r\n",
    "- c'è un unico id_ram con associati 64 venditori (4377) (OK)\r\n",
    "- il venditore con meno vendite (7) sembra essere Monoprice, che vende solo 4 modelli non uguali\r\n",
    "- il venditore con più id_ram diverse vendute (1733) semrba essere geizhals_unknown, con totale (max)\r\n",
    "    vendite a 2043095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and CONTINENT Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"continent\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique()#.value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "x = \"continent\"\r\n",
    "y = \"id_ram\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(y1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_join[df_join[\"continent\"] == \"Europe\"]\r\n",
    "df_temp = df_temp.groupby(\"id_ram\")[\"continent\"].nunique()\r\n",
    "print(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 1036 id_ram diversi associati ad un unico continente \r\n",
    "- ci sono 1122 id_ram diversi associati a tutti e 3 i continenti\r\n",
    "- L'Europa è il continente con il maggior numero (825) di modelli di ram venduti esclusivamente \r\n",
    "- Il continente con meno id_ram diverse importate (1548) è l'America\r\n",
    "- Il continente con più id_ram diverse importate (2904) è l'Europa\r\n",
    "- Oceania dovrebbe essere il continente con meno ram vendute/importate\r\n",
    "- L'Europa è il continente con più ram vendute/importate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"id_ram\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(y1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 280 id_ram diversi con associati un unica nazione (OK)\r\n",
    "- ci sono 128 id_ram diversi associati a 11 nazioni (OK)\r\n",
    "- ci sono però 1176 id_ram diversi che hanno associate solo 2 nazioni\r\n",
    "- l'Italia è la nazione con meno id_ram diverse vendute (238)\r\n",
    "- la Germania è la nazione con il maggior numero di ram diverse vendute (2324)\r\n",
    "- gli USA hanno acquistato (con esclusiva) 147 ram diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM and REGION Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"id_ram\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"id_ram\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(y1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 18 ram diverse acquistate in esclusiva da un unica regione (OK)\r\n",
    "- c'è una ram acquistata da 75 regioni (OK) (id_ram 5756)\r\n",
    "- la regione che ha acquistato meno ram diverse è la north island-central east (Oceania)\r\n",
    "- la regione con il maggior numero di ram diverse vendute è la saarland (Europa)\r\n",
    "- la regione con meno ram acquistate (non uniche) (126) è south italy (Europe)\r\n",
    "- la regione con più ram acquistate (non uniche) (144085) è saxony-anhalt (??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - TIME_CODE and BRAND Attributes\t\t- ?&V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"time_code\"\r\n",
    "y = \"brand\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"time_code\"\r\n",
    "x = \"brand\"\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un unico giorno dove hanno acquistato 9 brand (OK) (2017-10-13)\r\n",
    "- c'è un unico giorno dove hanno acquistato 41 brand (OK) (2018-04-08)\r\n",
    "- i brand che hanno acquistato meno giorni (2) (unici) sono DANE-ELEC e GALAX/KFA2\r\n",
    "- i brand che hanno acquistato in più giorni (unici) sono (7)\r\n",
    "- il giorno che si è acqusitato meno ram (non uniche) (172) è 2017-08-22\r\n",
    "- il giorno che si è acqusitato meno ram (non uniche) (8052) è 2018-04-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - WEEK and COUNTRY Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "y = \"week\"\r\n",
    "x = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un unica nazione (Italia) con 26 settimane associate (OK)\r\n",
    "- 9 nazioni che vendono tutto l'anno (OK)\r\n",
    "- le settimane dove si vendono meno ram (uniche) (9) sono la 16-17-18-22\r\n",
    "- le settimane dove si vendono più ram (uniche) (11) sono 26 totali (1..15)(41...53)\r\n",
    "- la settimana con meno acquisti totali è la 1 (35641)\r\n",
    "- la settimana con più acquisti totali è la 12 (71950)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - SALES_USD and BRAND Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"sales_usd\"\r\n",
    "y = \"brand\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"sales_usd\"\r\n",
    "x = \"brand\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- 2818449 prezzi (USD) hanno un unico brand associato (OK)\r\n",
    "    - può voler dire che è il brand con più variazione nei prezzi o cmq con più cambi di prezzi\r\n",
    "- ci sono 17 brand con soli 3 prezzi diversi per i propri modelli (OK)\r\n",
    "- il brand con meno prezzi associati non-unici (2) è DANE-ELEC\r\n",
    "- il brand con più prezzi associati non-unici (723593) è G.SKILL\r\n",
    "- il prezzo maggiormente adottato è 89.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - SALES_USD and VENDOR Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"sales_usd\"\r\n",
    "y = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"sales_usd\"\r\n",
    "x = \"vendor\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un vendor con 2878768 prezzi diversi per le proprie ram (OK) (pricespy_unknown ???)\r\n",
    "    - può voler dire che è il vendor con più variazione nei prezzi o cmq con più cambi di prezzi\r\n",
    "- ci sono 13 vendor con soli 5 prezzi diversi per i propri modelli (OK)\r\n",
    "- il vendor con meno prezzi (4) non unici è Monoprice\r\n",
    "- il vendor con più prezzi (1824646) non unici è geizhals_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CURRENCY and MEMORY_TYPE Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"currency\"\r\n",
    "y = \"memory_type\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"currency\"\r\n",
    "x = \"memory_type\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 3 valute (NZD-AUD-GBP) uniche con associate 3 tipologie di ram (OK)\r\n",
    "- c'è una valuta (EUR) con associati 7 tecnologie ram (OK)\r\n",
    "- le tecnologie con più valute associate sono DDR2, DDR3, DDR4\r\n",
    "- la valuta con meno prodotti venduti (56648) è NZD\r\n",
    "- la valuta con più prodotti venduti (2374526) è EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CURRENCY and VENDOR Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "y = \"currency\"\r\n",
    "x = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 25 venditori che usano una sola valuta (OK)\r\n",
    "- c'è un venditore (Mighty Ape) che vende in 4 valute (OK)\r\n",
    "- la valuta con meno venditori (non-unici) (8) è CAD\r\n",
    "- la valuta con meno venditori (non-unici) (37) è EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CURRENCY and CONTINENT Attributes\t- ?&NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"currency\"\r\n",
    "y = \"continent\"\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"currency\"\r\n",
    "x = \"continent\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 2 valute per continente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CURRENCY and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"currency\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"currency\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- L'EURO con cui è possibile comprare nel maggior numero di nazioni (6)\r\n",
    "- le altre valute possono acquistare in un'unica nazione\r\n",
    "- ci sono 11 nazioni "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CURRENCY and REGION Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"currency\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"currency\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- L'euro è utilizzato da 38 regioni, la valuta più utilizzata\r\n",
    "- ci sono 2 valute (CAD-AUD) utilizzate da 6 regioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and WEEK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"week\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"week\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un brand (PAREEMA) che vende solo una settimana dell'anno (16) (potrei rimuovere in quanto outlier)\r\n",
    "    - ci sono 3 brand che vendono solo 2 settimane dell'anno (potrei rimuovere in quanto outlier)\r\n",
    "- 35(37)(38) brand vendono tutto l'anno\r\n",
    "- le settimane in cui hanno acquistato meno brand (39) sono 21-53\r\n",
    "- le settimane in cui hanno acquistato più brand (45) sono 11-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and CURRENCY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"currency\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"currency\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 14 brand che vendono con una sola valuta (OK)\r\n",
    "- ci sono 12 brand che vendono in tutte le valute del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and RAM_MODEL Attributes\t\t- ?&V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"ram_model\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"ram_model\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 27 brand che hanno un unico modello di ram\r\n",
    "- c'è un brand (MUSHKIN) con 39 prodotti\r\n",
    "- ci sono 279 brand che hanno un solo ram_model\r\n",
    "- c'è un modello (Galax Hof) che ha 2 brand associati (OUTLIERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and MEMORY_DIM Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"memory_dim\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"memory_dim\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 9 brand che vendono memorie di un unica dimensione (OK)\r\n",
    "- c'è 1 brand che vende memorie con 17 diverse dimensioni (CRUCIAL)\r\n",
    "- le dimensioni di memoria con un unico brand sono 0.12-96-256\r\n",
    "- le dimensioni di memoria con più brand (38) è 8GB\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and MEMORY_TYPE Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"memory_type\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"memory_type\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 13 brand che vendono memorie di un unica tipologia (OK)\r\n",
    "- ci sono 3 brand (G.SKILL-KINGSTON-MUSHKIN) che vendono memorie di tutte le tipologie (OK)\r\n",
    "- la tipologia di memoria con meno brand (1) è DDR3U (esclusiva)\r\n",
    "- la tipologia di memoria con più brand (40) è DDR3 (esclusiva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and CLOCK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"clock\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"clock\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 10 brand che vendono memorie con un unica frequenza di clock (OK)\r\n",
    "- c'è un unico brand (CORSAIR) che vende memorie con 37 frequenze di clock (OK)\r\n",
    "- ci sono 7 frequenze di clock vendute da un unico brand\r\n",
    "- la frequenza venduta da più brand (36) è la 1600\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and VENDOR Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"vendor\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un brand (CORSAIR) che vende a 72 venditori (OK)\r\n",
    "- ci sono 16 brand che vendono ad un unico venditore (OK)\r\n",
    "- ci sono 4 venditori che vendono ad un unico brand \r\n",
    "- c'è 1 venditore (geizhals_unknown) che vende a più brand (30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and CONTINENT Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"continent\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"continent\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 16 brand che vendono in un unico continente (OK)\r\n",
    "- ci sono 23 brand che vendono in tutti i continenti (OK)\r\n",
    "- il continente che vende a meno brand (28) è l'America\r\n",
    "- il continente che vende a più brand (46) è l'Europa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 4 brand che vendono in un unica nazione (OK)\r\n",
    "- ci sono 6 brand che vendono in tutte (11) le nazioni (OK)\r\n",
    "- le nazioni che hanno meno brand (9) sono France e Italy\r\n",
    "- la nazione che ha più brand (38) sono Germany\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - BRAND and REGION Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"brand\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"brand\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un brand (DAN-ELEC) che vende in una sola regione (west-midlands)\r\n",
    "- ci sono 3 brand che vendono in 75 regioni (OK)\r\n",
    "- i brand che vendono in meno regioni (4) sono 3 \r\n",
    "- i brand che vendono in più regioni (34) sono 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and TIME_CODE Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"time_code\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp.head(30))\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().reset_index(name=\"new_\" + y)\r\n",
    "print(df_temp[df_temp.new_time_code == 1])\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"time_code\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono alcuni modelli di ram con pochissimi time_code associati, \r\n",
    "    in particolare c'è una ram (Kingston Lv Xmp 10Th Anniversary) con associato un solo time_code,\r\n",
    "        (non necessariamente a motivare un singolo acquisto effettuato)\r\n",
    "- c'è un modello di ram con associati 96 timecode\r\n",
    "- il giorno in cui sono venduti meno modelli di ram (33) è il 2017-12-10\r\n",
    "- il giorno in cui sono venduti più modelli di ram (232) è il 2018-04-08\r\n",
    "- ci sono 6 ram model che hanno venduto di più (1840) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and WEEK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"week\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"week\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 3 ram_model associati ad una sola settimana (16) (OK)\r\n",
    "- gran parte dei ram_model (186) sono a copertura di tutte le settimane (OK)\r\n",
    "- la settimana con meno ram_model venduti (215) è la 29\r\n",
    "- la settimana con meno ram_model venduti (249) è la 14\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and SALES_USD Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"sales_usd\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"sales_usd\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 2 ram_model con solo un prezzo associato (OK)\r\n",
    "- c'è un ram_model (Corsair Vengeance) con 243577 prezzi USD associati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and SALES_CURRENCY Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"sales_currency\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"sales_currency\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 11 ram_model con solo un prezzo associato (OK)\r\n",
    "- c'è un ram_model (Corsaire Vengeance) con 116017 prezzi (diverse valute) associati (OK)\r\n",
    "- ci sono 263639 prezzi associati ad un ram model\r\n",
    "- il prezzo con più ram_model presenti è 49.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and MEMORY_TYPE Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"memory_type\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"memory_type\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 160 ram_model con un unica tecnologia associata\r\n",
    "- ci sono 2 ram_model (Kingston Valueram, Mushkin Essentials) con associati tutte le tipologie di ram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and MEMORY_DIM Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"memory_dim\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"memory_dim\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 59 ram_model con associati solo una dimensione di ram (OK)\r\n",
    "- c'è un ram_model (Crucial) con associate 17 dimensioni per la ram \r\n",
    "- la dimensione di memoria con associato un unico ram_model (Kingston Valueram) è 0.12\r\n",
    "- la dimensione di memoria con associato 203 ram_model è 8GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and CLOCK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"clock\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"clock\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 80 ram_model con associati una sola frequenza di clock per ognuno (OK)\r\n",
    "- c'è un ram_model (Corsair Vengeance) che ha 26 frequenze di clock (OK)\r\n",
    "- ci sono 6 frequenze di clock con associati un unico ram_model\r\n",
    "- la frequenza (1600) è quella con più ram_model associati (164)\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and VENDOR Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"vendor\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 115 ram_model con associate ognuna un unico venditore (OK)\r\n",
    "- c'è un ram_model (Corsair Vengeance) con associato 70 venditori (OK)\r\n",
    "- ci sono 4 venditori con il minor numero di ram_model associati (3)\r\n",
    "- c'è un venditore (geizhals_unknown) con il maggior numero di ram_model associati (162)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and CONTINENT Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"continent\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"continent\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 87 ram_model collegati ad un unico continente (di cui 80 solo in Europa) (OK)\r\n",
    "- ci sono 112 ram_model che vendono in tutti i continenti (OK)\r\n",
    "- l'America è il continente con meno ram_model associati (141)\r\n",
    "- l'Europa è il continente con più ram_model associati (273)\r\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 14 ram_model venduti in un unica nazione (10 di cui in UK) (OK)\r\n",
    "- ci sono 29 ram_model venduti in 11 nazioni (OK)\r\n",
    "- l'italia è la nazione con associati meno ram_model (44)\r\n",
    "- la Germania è la nazione con associati più ram_model (217)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - RAM_MODEL and REGION Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"ram_model\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"ram_model\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 2 ram_model venduti in un unica regione (OK)\r\n",
    "- ci sono 5 ram_model venduti in 75 regioni (OK)\r\n",
    "- la regione con meno ram_model venduti (23) è north italy\r\n",
    "- le regioni con più ram_model venduti (188) sono 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - MEMORY_DIM and CURRENCY Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"memory_dim\"\r\n",
    "y = \"currency\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"memory_dim\"\r\n",
    "x = \"currency\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 2 dimensioni di memoria con associata una sola valuta (EURO, 128-250MB) (OK)\r\n",
    "- ci sono 13 dimensioni di memoria con associate tutte le valute (OK)\r\n",
    "- le valute con associate meno dimensioni di memoria (13) sono CAD e NZD\r\n",
    "- la valuta con associata meno dimensioni di memoria (18) è l'EUR\r\n",
    "- la dimensione di memoria venduta meno (870) è 256GB\r\n",
    "- la dimensione di memoria venduta meno (829243) è 8GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CLOCK and MEMORY_TYPE Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"clock\"\r\n",
    "y = \"memory_type\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x)\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"clock\"\r\n",
    "x = \"memory_type\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 29 clock con associati una sola tipologia di memoria (OK)\r\n",
    "- c'è un solo clock (1600) con associato 4 tipi di memoria\r\n",
    "- la tipologia di ram con associati meno frequenze di clock (1) è DDR3U\r\n",
    "- la tipologia di ram con associati più frequenze di clock (25) è DDR4\r\n",
    "- la frequenza di clock con meno vendite (28) è la 3666\r\n",
    "- la frequenza di clock con più vendite (699161) è la 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CLOCK and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"clock\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"clock\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è una frequenza di clock (3666) associata ad una sola nazione (America) (OK)\r\n",
    "- ci sono 16 frequenze di clock vendute in 11 nazioni (OK)\r\n",
    "- l'Italia è la nazione con meno frequenze di clock associate (18)\r\n",
    "- le nazioni con più freq. di clock associate (41) sono Germania e Spagna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CLOCK and REGION Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"clock\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x)\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"clock\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è una frequenza (3666) di clock associata a 7 regioni (OK)\r\n",
    "- ci sono 10 frequenze di clock presenti in 75 regioni (OK)\r\n",
    "- le regioni con associate meno freq. di clock (12) sono 2\r\n",
    "- le regioni con associate più freq. di clock (41) sono 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - VENDOR and TIME_CODE Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"vendor\"\r\n",
    "y = \"time_code\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(y)[x].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x)\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"vendor\"\r\n",
    "x = \"time_code\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un venditore con associati solo 2 time code\r\n",
    "- c'è un unico venditore che ha 1831 time_code\r\n",
    "- ci sono 723 time code con un solo venditore associato\r\n",
    "- ci sono 2 time code con il maggior numero di venditori associato (74)\r\n",
    "- Monoprice è il venditore con associati meno time_code (2)\r\n",
    "- geizhals_unknown è il venditore con associati più time_code (1831)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - VENDOR and WEEK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"vendor\"\r\n",
    "y = \"week\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"vendor\"\r\n",
    "x = \"week\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un venditore (Monoprice) che ha venduto in 2 sole settimane (OK)\r\n",
    "- ci sono 40 venditori che vendono in tutto l'anno (OK)\r\n",
    "- le settimane con meno venditori (49) sono la 17 e la 18\r\n",
    "- la settimana con più venditori (76) è la 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - VENDOR and MEMORY_TYPE Attributes\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"vendor\"\r\n",
    "y = \"memory_type\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"vendor\"\r\n",
    "x = \"memory_type\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- c'è un venditore (YoYoTech) che vende una sola tipologia di ram (DDR4) (OK)\r\n",
    "- c'è un venditore (geizhals_unknown) che vende tutte le tipologie di ram (7) \r\n",
    "- ci sono 3 tipologie di ram con un unico venditore associato\r\n",
    "- ci sono 2 tipologie di ram con più venditori associati (77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - VENDOR and CONTINENT Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"vendor\"\r\n",
    "y = \"continent\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"vendor\"\r\n",
    "x = \"continent\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 53 venditori che vendono in 2 contenti, mentre 25 in un unico continente (di cui 14-11 America,Europa) (OK)\r\n",
    "- l'America è il continente con meno venditori (22)\r\n",
    "- l'Europa è il continente con più venditori (64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - VENDOR and COUNTRY Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"vendor\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"vendor\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 14 venditori che vendono in un unica nazione (USA) (OK)\r\n",
    "- ci sono 3 venditori che vendono in 4 nazioni (OK)\r\n",
    "- l'Italia è la nazione con meno venditori (3)\r\n",
    "- l'Australia è la nazione con più venditori (35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CONTINENT and COUNTRY Attributes\t\t- V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"continent\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"continent\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- sono presenti 2 continenti con 2 nazioni (America, Oceania)\r\n",
    "- il continente con più regioni (7) è l'Europa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CONTINENT and REGION Attributes\t\t- ?&V, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"continent\"\r\n",
    "y = \"region\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"continent\"\r\n",
    "x = \"region\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- America e Oceania presentano 13 regioni ognuna\r\n",
    "- l'Europa ne presenta 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - REGION and WEEK Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"region\"\r\n",
    "y = \"week\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"region\"\r\n",
    "x = \"week\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 59 regioni dove si vende tutto l'anno (OK)\r\n",
    "- ci sono 3 regioni che hanno venduto in sole 5 settimane dell'anno (OK)\r\n",
    "- le settimane con meno regioni sono la 17-18\r\n",
    "- le settimane con più regioni sono la 11..14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - REGION and CURRENCY Attributes\t\t- ?&NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"region\"\r\n",
    "y = \"currency\"\r\n",
    "df_temp = df_join.groupby(y)[x].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + x + \" , WHILE THE 2ND is \" + y)\r\n",
    "print(\"We want to verify if some value of \" + y + \" is associated with more than one value of \" + x)\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"region\"\r\n",
    "x = \"currency\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 38 regioni che usano l'EURO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - REGION and VENDOR Attributes\t\t- NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"region\"\r\n",
    "y = \"vendor\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"region\"\r\n",
    "x = \"vendor\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- ci sono 6 regioni con associate un unico venditore (OK)\r\n",
    "- c'è un unica regione con 35 venditori (queensland)\r\n",
    "- ci sono 2 venditori con 3 regioni\r\n",
    "- il venditore che vende in più regioni (28) è Alternate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - REGION and COUNTRY Attributes\t\t- ?&NV, \r\n",
    "\r\n",
    "FATTO -> verifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIFIC CASE\r\n",
    "x = \"region\"\r\n",
    "y = \"country\"\r\n",
    "df_temp = df_join.groupby(x)[y].nunique().value_counts().sort_index()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].unique().value_counts()\r\n",
    "print(\"\\n-----------REMEMBER THAT THE FIRST ATTRIBUTE SHOWED IS \" + y + \" , WHILE THE 2ND is \" + x)\r\n",
    "print(\"We want to verify if some value of \" + x + \" is associated with more than one value of \" + y )\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby(x)[y].value_counts()\r\n",
    "print()\r\n",
    "print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y normali -------------------------------------\")\r\n",
    "y = \"region\"\r\n",
    "x = \"country\"\r\n",
    "\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x)[y].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")   \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------x e y invertiti -------------------------------------\")\r\n",
    "y1 = x\r\n",
    "x1 = y\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1)[y1].nunique().reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp1[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\")    \r\n",
    "\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"count\"] == df_temp[\"count\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()\r\n",
    "for index, z in enumerate(df_temp2[x1]):\r\n",
    "    if index < 3:\r\n",
    "        print(df_join[df_join[x1] == z].head(3))\r\n",
    "        print(\"######################################\")\r\n",
    "print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-..-.-.-.-.-.-.-.-\") \r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\n####-------------------------counts su x e y invertiti -------------------------------------\")\r\n",
    "\r\n",
    "df_temp=df_join.groupby(x1).count()#.reset_index(name=\"count\")\r\n",
    "#.sort_index()\r\n",
    "#print(df_temp)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MIN Considerations::\\n\\n\")\r\n",
    "\r\n",
    "\r\n",
    "#MIN:\r\n",
    "\r\n",
    "df_temp1 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].min()]\r\n",
    "print(df_temp1)\r\n",
    "print()\r\n",
    "\r\n",
    "print(\"MAX Considerations::\\n\")\r\n",
    "print()\r\n",
    "\r\n",
    "\r\n",
    "#MAX:    \r\n",
    "\r\n",
    "df_temp2 = df_temp[df_temp[\"id_ram\"] == df_temp[\"id_ram\"].max()]\r\n",
    "print(df_temp2)\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- Germania e UK hanno il maggior numero di regioni (16-11)\r\n",
    "- Belgio e Italia sono le nazioni con meno regioni "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - ID_RAM Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------  ID → Quanto ogni singolo modello (specifico) è stato venduto\r\n",
    "df_temp = df_join.groupby('id_ram')['id_ram'].count()\r\n",
    "print(\"\\nThe model that sold the most is :: \\t\", df_temp.idxmax()) \r\n",
    "print(\"The model that sold the least is :: \\t\", df_temp.idxmin())\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "df_temp = df_join.groupby('id_ram').nunique()#.reset_index(name=\"count\")\r\n",
    "print(df_temp)\r\n",
    "print()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSA POSSO TRARRE:\r\n",
    "- mi sono accorto che l'attributo id_ram non identifica la vendita o il carrello, ma l'insieme delle componenti identificative per la ram\r\n",
    "    è un codice univoco per ogni combinazione di caratteristiche della RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--1.8---------------------  Distributions  -----------------------------------\r\n",
    "\r\n",
    "# --------------   histograms  ---------------\r\n",
    "mpl.rc('figure', max_open_warning = 0) #perchè 21 attributi\r\n",
    "sturge_number = math.trunc(np.log2(len(df_join)))\r\n",
    "for col in df_join:  \r\n",
    "    print(\"\\n\\nCONSIDERATIONS ABOUT THE ATTRIBUTE: \" + col)\r\n",
    "    df_join[col].hist(bins = sturge_number + 1)  #Sturges' rule\r\n",
    "    pl.suptitle(col)    \r\n",
    "    plt.savefig(dir+'\\\\Histogram\\\\'+col+'-hist.jpg')\r\n",
    "    plt.xticks(rotation=45)\r\n",
    "    plt.figure(figsize = (10,8))\r\n",
    "    plt.show()\r\n",
    "    print()\r\n",
    "\r\n",
    "    print('\\nThe number of unique values for the attribute ' + col + ' is:')\r\n",
    "    print(df_join[col].nunique())\r\n",
    "    print()\r\n",
    "\r\n",
    "#   per vedere il conteggio dei valori \r\n",
    "    print('\\nThe values count for the attribute ' + col + ' is:')\r\n",
    "    print(df_join[col].value_counts())\r\n",
    "    print()\r\n",
    "    df_join[col].value_counts().to_csv('D:\\\\Dropbox\\\\Scuola\\\\Pisa\\\\Anno2\\\\Data Mining\\\\Esame\\\\Pratica\\\\python\\\\NewDataset\\\\Value Count\\\\'+col+'-value-count.csv')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSIDERAZIONI:\r\n",
    "- c'è da controllare la distribuzione su sales_usd, sales_currency, memory_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\r\n",
    "- highest and lowest sales_usd\r\n",
    "    - decido di lavorare solo sales_usd e poi rimuoverò sales_currency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers da Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#-------------- il brand che ha venduto meno è DANE-ELEC\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- i brand che hanno venduto meno giorni (2) (unici) sono DANE-ELEC e GALAX/KFA2\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- il modello che è stato venduto un unica volta è il Kingston Lv Xmp 10Th Anniversary\r\n",
    "    #-------------perchè sembra essere un edizione speciale\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- il venditore con meno vendite (7) sembra essere Monoprice, che vende solo 4 modelli non uguali\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- la regione con meno ram acquistate (non uniche) (126) è south italy (Europe) (FORSE!!)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- c'è un brand (PAREEMA) che vende solo una settimana dell'anno (16) (potrei rimuovere in quanto outlier)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- ci sono 3 brand che vendono solo 2 settimane dell'anno (potrei rimuovere in quanto outlier)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- c'è un modello (Galax Hof) che ha 2 brand associati (OUTLIERS)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- i brand che vendono in meno regioni (4) sono 3 (CONTROLLARE LE QUANTITA' DI VENDITE)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- ci sono 2 ram_model venduti in un unica regione (OK)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- la dimensione di memoria con associato un unico ram_model (Kingston Valueram) è 0.12 (CONTROLLO)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "#-------------- ci sono 4 venditori con il minor numero di ram_model associati (3)\r\n",
    "outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "df_join.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "\r\n",
    "\r\n",
    "id_ram con un solo time_code associato\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080.9298809906722\n",
      "       time_code  sales_usd  sales_currency   brand  ram_model  memory_dim  \\\n",
      "count    3109.00    3109.00         3109.00 3109.00    3109.00     3109.00   \n",
      "mean     1080.93    1080.93         1080.93 1080.93    1080.93     1080.93   \n",
      "std      1240.95    1240.95         1240.95 1240.95    1240.95     1240.95   \n",
      "min         1.00       1.00            1.00    1.00       1.00        1.00   \n",
      "25%       107.00     107.00          107.00  107.00     107.00      107.00   \n",
      "50%       619.00     619.00          619.00  619.00     619.00      619.00   \n",
      "75%      1813.00    1813.00         1813.00 1813.00    1813.00     1813.00   \n",
      "max      8840.00    8840.00         8840.00 8840.00    8840.00     8840.00   \n",
      "\n",
      "       memory_type   clock  vendor  continent  country  region  currency  \\\n",
      "count      3109.00 3109.00 3109.00    3109.00  3109.00 3109.00   3109.00   \n",
      "mean       1080.93 1080.93 1080.93    1080.93  1080.93 1080.93   1080.93   \n",
      "std        1240.95 1240.95 1240.95    1240.95  1240.95 1240.95   1240.95   \n",
      "min           1.00    1.00    1.00       1.00     1.00    1.00      1.00   \n",
      "25%         107.00  107.00  107.00     107.00   107.00  107.00    107.00   \n",
      "50%         619.00  619.00  619.00     619.00   619.00  619.00    619.00   \n",
      "75%        1813.00 1813.00 1813.00    1813.00  1813.00 1813.00   1813.00   \n",
      "max        8840.00 8840.00 8840.00    8840.00  8840.00 8840.00   8840.00   \n",
      "\n",
      "        month    week  \n",
      "count 3109.00 3109.00  \n",
      "mean  1080.93 1080.93  \n",
      "std   1240.95 1240.95  \n",
      "min      1.00    1.00  \n",
      "25%    107.00  107.00  \n",
      "50%    619.00  619.00  \n",
      "75%   1813.00 1813.00  \n",
      "max   8840.00 8840.00  \n"
     ]
    }
   ],
   "source": [
    "test=df_join.groupby(\"id_ram\").count().sort_values(by=\"time_code\", ascending=True)\r\n",
    "test.head(50)\r\n",
    "\r\n",
    "import statistics\r\n",
    "list2 = test[\"time_code\"].tolist()\r\n",
    "print(statistics.mean(list2))\r\n",
    "\r\n",
    "print(test.describe())\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--1.9---------------------  Box Plots & Outliers  ----------------------------\r\n",
    "    \r\n",
    "for col in num_float:  \r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    ax.set_title('\\nOutliers of ' +col+ ' in the Dataset')\r\n",
    "    ax.boxplot(df_join[col])\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    print(\"---------------------------------------------------------------\")\r\n",
    "    \r\n",
    "    \r\n",
    "attr_outliers=[\"sales_usd\"]\r\n",
    "\"\"\"for col in attr_outliers:\r\n",
    "    df_join['zscore']=(df_join[col]-df_join[col].mean())/df_join[col].std()\r\n",
    "    df_join[col] = np.where(df_join['zscore']<-3, df_join[col].mean(), df_join[col])\r\n",
    "    df_join[col] = np.where(df_join['zscore']>3, df_join[col].mean(), df_join[col])\r\n",
    "\r\n",
    "#   \"PROVA DEL 9\" - memory_dim NON restituisce 0\r\n",
    "for col in attr_outliers:\r\n",
    "    df_join['zscore']=(df_join[col]-df_join[col].mean())/df_join[col].std()\r\n",
    "    print(df_join[(df_join['zscore']<-3) | (df_join['zscore']>3)].shape[0])    #deve restituire tutti 0\r\n",
    "\r\n",
    "del df_join['zscore']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_values(s):\r\n",
    "    q1 = s.quantile(q = 0.15)\r\n",
    "\r\n",
    "    q3 = s.quantile(q = 0.75)    \r\n",
    "\r\n",
    "    iqr = q3 - q1\r\n",
    "\r\n",
    "    #iqr_left = q1 - 2*iqr\r\n",
    "    \r\n",
    "    iqr_right = q3 + 2*iqr\r\n",
    "    \r\n",
    "    return q1, iqr_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join[\"sales_usd\"].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.sales_usd.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.sales_usd.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"sales_usd\"\r\n",
    "\r\n",
    "print(\"OUTLIERS REPRESENTATION FOR ATTRIBUTE :\\t\" + x)\r\n",
    "left_sale, right_sale = iqr_values(df_join[x])\r\n",
    "df_join[(df_join[x] > left_sale) & (df_join[x] < right_sale)][x].plot.box()\r\n",
    "plt.show()\r\n",
    "print()\r\n",
    "outliers = df_join[(df_join[x] < left_sale) | (df_join[x] > right_sale)]\r\n",
    "print(\"\\n Outliers founded\")\r\n",
    "print()\r\n",
    "print(outliers.describe())\r\n",
    "print()\r\n",
    "print(\"--------------------------------------------------\")\r\n",
    "print(\"\\n Dataset dropped\")\r\n",
    "df_dropped = df_join[(df_join[x] > left_sale) & (df_join[x] < right_sale)]\r\n",
    "print(df_dropped.describe())\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[\"sales_usd\"].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[\"sales_usd\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[\"sales_usd\"].kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.drop(labels='week', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--1.6---------------------  Correlation  -------------------------------------\r\n",
    "\r\n",
    "print(\"\\nCorrelation Matrix with Pearson::\")\r\n",
    "corr = df_dropped.corr(method='pearson')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "#plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nCorrelation Matrix with Spearman::\")\r\n",
    "corr = df_dropped.corr(method='spearman')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "#plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"\\nHeatmap correlation::\")\r\n",
    "sns.heatmap(df_dropped.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation by scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\r\n",
    "plt.scatter(df_dropped[\"sales_usd\"], df_dropped[\"sales_currency\"])\r\n",
    "plt.xlabel(\"sales_usd\")\r\n",
    "plt.ylabel(\"sales_currency\")\r\n",
    "plt.title('\\nCorrelation between sales_usd and sales_currency')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\r\n",
    "-1.7---------------------  Visualization  ------------------------------\r\n",
    "\"\"\"histograms are used to show distributions of variables \r\n",
    "while bar charts are used to compare variables. \r\n",
    "Histograms plot binned quantitative data \r\n",
    "while bar charts plot categorical data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar charts (WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------bar charts / Categorical attributes and comparing variables\r\n",
    "for x in df_dropped.columns:\r\n",
    "    plt.figure(figsize = (20,10))\r\n",
    "    if x != \"time_code\":\r\n",
    "        df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[x].nunique().plot(kind=\"bar\", title=\"test\")\r\n",
    "        plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "        plt.title(x)\r\n",
    "        plt.xlabel(\"Group by Years and Months\")\r\n",
    "        plt.ylabel(\"nunique()\")\r\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.groupby(df_dropped.time_code.dt.year)['id_ram'].count().plot(kind=\"bar\", title=\"test\")\r\n",
    "plt.xticks(rotation=30, horizontalalignment=\"center\")\r\n",
    "plt.title(\"Number of purchases of ram per year\")\r\n",
    "plt.xlabel(\"Years\")\r\n",
    "plt.ylabel(\"Rams bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped['time_code'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped['time_code'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel 2013 la partenza dei dati è a Marzo e copre 8 mesi mentre nel 2018 i dati finiscono ad aprile e la colonna copre solo i primi 4 mesi circa\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.groupby('continent')['id_ram'].count().plot(kind=\"bar\", title=\"test\")\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.xticks(rotation=30, horizontalalignment=\"center\")\r\n",
    "plt.title(\"Number of purchases of ram per continent\")\r\n",
    "plt.xlabel(\"Continent\")\r\n",
    "plt.ylabel(\"Rams bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('vendor')['id_ram'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most selling vendors\")\r\n",
    "plt.ylabel(\"Vendors\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('brand')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most selling Brands\")\r\n",
    "plt.ylabel(\"Brand\")\r\n",
    "plt.xlabel(\"Rams sold\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('brand')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.tail(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"10 less selling Brands\")\r\n",
    "plt.ylabel(\"Brand\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('brand')['id_ram'].nunique().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh(stacked=True)\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most selling Brands\")\r\n",
    "plt.ylabel(\"Vendors\")\r\n",
    "plt.xlabel(\"Rams sold\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('ram_model')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most selling ram models\")\r\n",
    "plt.ylabel(\"Ram Model\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('ram_model')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.tail(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"10 less selling ram models\")\r\n",
    "plt.ylabel(\"Ram Model\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('memory_dim')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most popular memory dimensions\")\r\n",
    "plt.ylabel(\"Memory Dims\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('memory_dim')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.tail(8)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"8 Least popular memory dimensions\")\r\n",
    "plt.ylabel(\"Memory Dims\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('memory_type')['time_code'].count().sort_values(ascending=False)\r\n",
    "#tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Most popular memory technologies\")\r\n",
    "plt.ylabel(\"Memory Type\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_dropped.groupby('clock')['time_code'].count().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(10)\r\n",
    "tmp.plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Top 10 Most popular clock frequencies\")\r\n",
    "plt.ylabel(\"Clock\")\r\n",
    "plt.xlabel(\"Rams sold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"continent\"\r\n",
    "y = \"memory_type\"\r\n",
    "\r\n",
    "plt.figure(figsize = (15,11))\r\n",
    "df_dropped.groupby(y)[x].nunique().plot.barh(stacked=True)\r\n",
    "#df_dropped.groupby(\"memory_type\")[\"brand\"].nunique().plot.barh(stacked=True)\r\n",
    "#plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Group by \" + y + \" and counting on \" + x)\r\n",
    "plt.xlabel(x)\r\n",
    "plt.ylabel(y)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in cat:\r\n",
    "    for y in cat:\r\n",
    "        if (x != y) & (x != \"id_ram\") & (x != \"time_code\") & (x != \"ram_model\"):\r\n",
    "            plt.figure(figsize = (15,11))\r\n",
    "            #df_dropped.groupby(x)[y].count().plot.barh(stacked=True)\r\n",
    "            df_dropped.groupby(x)[y].nunique().plot.barh(stacked=True)\r\n",
    "            #df_dropped.groupby(x)[y].value_counts().plot.barh(stacked=True)\r\n",
    "            #plt.style.use('ggplot')\r\n",
    "            plt.gca().invert_yaxis()\r\n",
    "            plt.title(\"Group by \" + x + \" and counting on \" + y)\r\n",
    "            plt.xlabel(y)\r\n",
    "            plt.ylabel(x)\r\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NON FUNZIONA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.figure(figsize = (20,10))\r\n",
    "df1 = df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.month])[\"sales_usd\"].sum()#.unstack()\r\n",
    "print(df1)\r\n",
    "df1[\"continent\"].plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "#df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[\"continent\"].nunique().plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "plt.title(x)\r\n",
    "plt.xlabel(\"Group by Years and Months\")\r\n",
    "plt.ylabel(\"sum\")\r\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked bar charts (WORK but WITHOUT \"Stacking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.groupby(df_dropped.time_code.dt.year).continent.value_counts().unstack(0).plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Number of purchases of ram per continent\")\r\n",
    "plt.ylabel(\"Continent\")\r\n",
    "plt.xlabel(\"Rams bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30,20]\r\n",
    "tmp=df_dropped.groupby('vendor').continent.value_counts().sort_values(ascending=False)\r\n",
    "tmp=tmp.head(15).unstack(0).plot.barh()\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.gca().invert_yaxis()\r\n",
    "plt.title(\"Number of purchases of ram per continent\")\r\n",
    "plt.ylabel(\"Continent\")\r\n",
    "plt.xlabel(\"Rams bought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30,20]\r\n",
    "df1 = df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month,'continent']).count().unstack()\r\n",
    "#plt.style.use('seaborn-dark-palette')\r\n",
    "#plt.style.use('ggplot')\r\n",
    "plt.style.use('fivethirtyeight')\r\n",
    "#plt.style.use('seaborn-muted')\r\n",
    "\r\n",
    "df1[\"time_code\"].plot(kind=\"bar\", stacked=True,sort_columns  =True)\r\n",
    "\r\n",
    "#df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[\"continent\"].nunique().plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "\r\n",
    "plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "plt.title(\"NotScaled\")\r\n",
    "plt.xlabel(\"Group by Years and Months\")\r\n",
    "plt.ylabel(\"sum\")\r\n",
    "\r\n",
    "\r\n",
    "#df1.plot(figsize=(20, 5))\r\n",
    "#plt.savefig('Contxsell')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30,20]\r\n",
    "df1 = df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month,'memory_type']).count().unstack()\r\n",
    "#plt.style.use('Solarize_Light2')\r\n",
    "#plt.style.use('seaborn-dark-palette')\r\n",
    "plt.style.use('fivethirtyeight')\r\n",
    "\r\n",
    "df1[\"time_code\"].plot(kind=\"bar\", stacked=True,sort_columns  =True)\r\n",
    "\r\n",
    "\r\n",
    "#df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[\"continent\"].nunique().plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "\r\n",
    "plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "\r\n",
    "plt.xlabel(\"Group by Years and Months\")\r\n",
    "plt.ylabel(\"sum\")\r\n",
    "\r\n",
    "\r\n",
    "#df1.plot(figsize=(20, 5))\r\n",
    "#plt.savefig('Contxsell')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30,20]\r\n",
    "for x in df_dropped.continent.unique():\r\n",
    "    df2=df_dropped[df_dropped.continent==x]\r\n",
    "    df1 = df_dropped.groupby([df2.time_code.dt.year , df2.time_code.dt.month,'memory_type']).count().unstack()\r\n",
    "    plt.style.use('Solarize_Light2')\r\n",
    "    plt.style.use('fivethirtyeight')\r\n",
    "\r\n",
    "    df1[\"time_code\"].plot(kind=\"bar\", stacked=True,sort_columns  =True)\r\n",
    "\r\n",
    "\r\n",
    "    #df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[\"continent\"].nunique().plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "    plt.title('Ram memory type popularity by year and month in '+x)\r\n",
    "    plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "\r\n",
    "    plt.xlabel(\"Group by Years and Months\")\r\n",
    "    plt.ylabel(\"sum\")\r\n",
    "\r\n",
    "\r\n",
    "    #df1.plot(figsize=(20, 5))\r\n",
    "    #plt.savefig('Contxsell')\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30,20]\r\n",
    "focus='memory_dim'\r\n",
    "for x in df_dropped.continent.unique():\r\n",
    "    df2=df_dropped[df_dropped.continent==x]\r\n",
    "    df1 = df_dropped.groupby([df2.time_code.dt.year , df2.time_code.dt.month,focus]).count().unstack()\r\n",
    "    plt.style.use('Solarize_Light2')\r\n",
    "\r\n",
    "    df1[\"time_code\"].plot(kind=\"bar\", stacked=True,sort_columns  =True)\r\n",
    "\r\n",
    "\r\n",
    "    #df_dropped.groupby([df_dropped.time_code.dt.year , df_dropped.time_code.dt.month])[\"continent\"].nunique().plot(kind=\"bar\", title=\"test\", stacked=True)\r\n",
    "    plt.title('Ram memory type popularity by year and month in '+x)\r\n",
    "    plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "\r\n",
    "    plt.xlabel(\"Group by Years and Months\")\r\n",
    "    plt.ylabel(\"sum\")\r\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.125),\r\n",
    "          ncol=int(df_dropped[focus].nunique()/4), fancybox=True, shadow=True)\r\n",
    "\r\n",
    "\r\n",
    "    #df1.plot(figsize=(20, 5))\r\n",
    "    #plt.savefig('Contxsell')\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie charts (WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------pie charts \r\n",
    "sns.set(font_scale=1.5)\r\n",
    "class_series = df_dropped.groupby('brand').size().sort_values(ascending=False)\r\n",
    "class_series.plot.pie(autopct='%.2f', figsize = (12,12), fontsize=(14), shadow = True)\r\n",
    "plt.title('Vendors Distribution')\r\n",
    "plt.savefig('D:\\\\Dropbox\\\\Scuola\\\\Pisa\\\\Anno2\\\\Data Mining\\\\Esame\\\\Pratica\\\\python\\\\NewDataset\\\\vendors-pie')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\r\n",
    "class_series = df_dropped.groupby('memory_type').size()\r\n",
    "class_series.plot.pie(autopct='%.2f', figsize = (12,12), fontsize=(14), shadow = True)\r\n",
    "plt.title('Memory Types Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\r\n",
    "class_series = df_dropped.groupby('continent').size()\r\n",
    "class_series.name = 'Continents Distribution'\r\n",
    "class_series.plot.pie(autopct='%.2f', figsize = (12,12), fontsize=(14), shadow = True)\r\n",
    "plt.title('Continents')\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donut charts (WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8,8]\r\n",
    "plt.rc('font', size=10)\r\n",
    "df=df_dropped\r\n",
    "layers = ['continent', 'country']\r\n",
    "value = 'amount'\r\n",
    "minimum_value = 2 # Skip values less than minimum\r\n",
    "\r\n",
    "df['amount'] = [1 for x in range(len(df))]\r\n",
    "city = df['country'].value_counts()\r\n",
    "city = city[city > minimum_value]\r\n",
    "df_big = df.loc[df['country'].isin(city.index)]   # reject small cities\r\n",
    "\r\n",
    "def percentage_growth(l):\r\n",
    "    s = 0\r\n",
    "    res = [0]\r\n",
    "    for i in range(len(l)-1):\r\n",
    "        s += l[i]\r\n",
    "        res.append(s / sum(l))\r\n",
    "    return res\r\n",
    "plt.axis(\"equal\")\r\n",
    "\r\n",
    "cmap = plt.get_cmap(\"rainbow\")\r\n",
    "\r\n",
    "for i, layer in enumerate(layers):\r\n",
    "    radius = i + 2\r\n",
    "    width = 1\r\n",
    "    frame = df_big.groupby(layers[:i+1])['amount'].sum()\r\n",
    "    colors = cmap(percentage_growth(frame))\r\n",
    "    labels = [x[-1] if isinstance(x, tuple) else x for x in frame.index.to_numpy()]\r\n",
    "    plt.pie(frame, labels=labels, colors=colors, radius=radius, wedgeprops=dict(width=width, edgecolor='w'), labeldistance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8,8]\r\n",
    "plt.rc('font', size=12)\r\n",
    "df=df_dropped\r\n",
    "layers = ['country','region']\r\n",
    "value = 'amount'\r\n",
    "minimum_value = 2 # Skip values less than minimum\r\n",
    "\r\n",
    "df['amount'] = [1 for x in range(len(df))]\r\n",
    "city = df['region'].value_counts()\r\n",
    "city = city[city > minimum_value]\r\n",
    "df_big = df.loc[df['region'].isin(city.index)]   # reject small cities\r\n",
    "\r\n",
    "def percentage_growth(l):\r\n",
    "    s = 0\r\n",
    "    res = [0]\r\n",
    "    for i in range(len(l)-1):\r\n",
    "        s += l[i]\r\n",
    "        res.append(s / sum(l))\r\n",
    "    return res\r\n",
    "plt.axis(\"equal\")\r\n",
    "\r\n",
    "cmap = plt.get_cmap(\"rainbow\")\r\n",
    "df_bigOld=df_big\r\n",
    "for x in df.continent.unique():\r\n",
    "    df_big=df_bigOld[df_bigOld.continent==x]\r\n",
    "    for i, layer in enumerate(layers):\r\n",
    "        radius = i + 2\r\n",
    "        width = 1\r\n",
    "        frame = df_big.groupby(layers[:i+1])['amount'].sum()\r\n",
    "        colors = cmap(percentage_growth(frame))\r\n",
    "        labels = [x[-1] if isinstance(x, tuple) else x for x in frame.index.to_numpy()]\r\n",
    "        plt.pie(frame, labels=labels, colors=colors, radius=radius, wedgeprops=dict(width=width, edgecolor='w'), labeldistance=0.8)\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot\r\n",
    "----------scatter plot 2D e 3D\tquantitative\r\n",
    "\"\"\"use density plots or plots based on binning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D (WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------2D\r\n",
    "\r\n",
    "#option1\r\n",
    "for x in df_dropped.columns:\r\n",
    "    for y in df_dropped.columns:\r\n",
    "        if x != y:\r\n",
    "            plt.figure(figsize = (15,11))\r\n",
    "            print(\"\\nScatter plot 2D for \" + x + \" and \" + y + \" ::\")\r\n",
    "            plt.scatter(df_dropped[x], df_dropped[y], s=5)\r\n",
    "            plt.show()\r\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option3 \r\n",
    "for x in df_dropped:\r\n",
    "    for y in df_dropped:\r\n",
    "        if (x != \"continent\") & (y != \"continent\") & (x != y):\r\n",
    "            plt.rcParams.update({'font.size': 7})\r\n",
    "            plt.rcParams[\"figure.figsize\"] = (15, 10)\r\n",
    "            plt.scatter(df_dropped[df_dropped['continent'] == 'Europe'][x], df_dropped[df_dropped['continent'] == 'Europe'][y], s=10, color='b', label='Europe')\r\n",
    "            plt.scatter(df_dropped[df_dropped['continent'] == 'Oceania'][x], df_dropped[df_dropped['continent'] == 'Oceania'][y], s=100, color='r', marker='*', label='Oceania')\r\n",
    "            plt.scatter(df_dropped[df_dropped['continent'] == 'America'][x], df_dropped[df_dropped['continent'] == 'America'][y], s=70, color='y', marker='+', label='America')\r\n",
    "            plt.xlabel(x)\r\n",
    "            plt.ylabel(y)\r\n",
    "            plt.legend(scatterpoints=1,\r\n",
    "                loc='lower left',\r\n",
    "                ncol=1,\r\n",
    "                fontsize=10)\r\n",
    "            #plt.savefig('D:\\\\Dropbox\\\\Scuola\\\\Pisa\\\\Anno2\\\\Data Mining\\\\Esame\\\\Pratica\\\\python\\\\NewDataset\\\\scatter2.jpg')\r\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix (WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------MATRIX\r\n",
    "#option ALL-IN --------------\r\n",
    "\"\"\"pd.plotting.scatter_matrix(df_join, marker='+', figsize = (20,20))\r\n",
    "plt.show()\"\"\"\r\n",
    "\r\n",
    "#option2\r\n",
    "#sns.set_theme(style=\"ticks\")\r\n",
    "sns.pairplot(df_dropped, hue=\"continent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def corrdot(*args, **kwargs):\r\n",
    "    corr_r = args[0].corr(args[1], 'pearson')\r\n",
    "    corr_text = round(corr_r, 2)\r\n",
    "    ax = plt.gca()\r\n",
    "    font_size = abs(corr_r) * 80 + 5\r\n",
    "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\", ha='center', va='center', fontsize=font_size)\r\n",
    "\r\n",
    "def corrfunc(x, y, **kws):\r\n",
    "    r, p = stats.pearsonr(x, y)\r\n",
    "    p_stars = ''\r\n",
    "    if p <= 0.05:\r\n",
    "        p_stars = '*'\r\n",
    "    if p <= 0.01:\r\n",
    "        p_stars = '**'\r\n",
    "    if p <= 0.001:\r\n",
    "        p_stars = '*'\r\n",
    "    ax = plt.gca()\r\n",
    "    ax.annotate(p_stars, xy=(0.65, 0.6), xycoords=ax.transAxes,\r\n",
    "                color='red', fontsize=70)\r\n",
    "\r\n",
    "sns.set(style='white', font_scale=1.6)\r\n",
    "\r\n",
    "g = sns.PairGrid(df_dropped, aspect=1.5, diag_sharey=False, despine=False)\r\n",
    "g.map_lower(sns.regplot, lowess=True, ci=False,\r\n",
    "            line_kws={'color': 'red', 'lw': 1},\r\n",
    "            scatter_kws={'color': 'black', 's': 20})\r\n",
    "g.map_diag(sns.distplot, color='black',\r\n",
    "           kde_kws={'color': 'red', 'cut': 0.7, 'lw': 1},\r\n",
    "           hist_kws={'histtype': 'bar', 'lw': 2,\r\n",
    "                     'edgecolor': 'k', 'facecolor':'grey'})\r\n",
    "g.map_diag(sns.rugplot, color='black')\r\n",
    "g.map_upper(corrdot)\r\n",
    "g.map_upper(corrfunc)\r\n",
    "g.fig.subplots_adjust(wspace=0, hspace=0)\r\n",
    "\r\n",
    "# Remove axis labels\r\n",
    "for ax in g.axes.flatten():\r\n",
    "    ax.set_ylabel('')\r\n",
    "    ax.set_xlabel('')\r\n",
    "\r\n",
    "# Add titles to the diagonal axes/subplots\r\n",
    "for ax, col in zip(np.diag(g.axes), df_dropped.columns):\r\n",
    "    ax.set_title(col, y=0.82, fontsize=26)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Line charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a grid of plots:\r\n",
    "fig = plt.figure(figsize=(25, 5))\r\n",
    "#fig_dims = (2, 1)\r\n",
    "fig.subplots_adjust(hspace=0.7)\r\n",
    "\r\n",
    "# # Plot mean sales \r\n",
    "# plt.subplot2grid(fig_dims, (0, 0))\r\n",
    "# monthly_sales_mean = df_join.groupby([df_join.year, df_join.month]).mean().plot()\r\n",
    "# plt.title('Mean value of Sale over the months: ', fontsize='x-large')\r\n",
    "# plt.xlabel('Year-Month', fontsize='x-large')\r\n",
    "# plt.ylabel('Mean Sale', fontsize='x-large')\r\n",
    "# plt.tick_params(labelsize='x-large')\r\n",
    "\r\n",
    "# Plot total sales\r\n",
    "#plt.subplot2grid(fig_dims, (1, 0))\r\n",
    "monthly_sales_total = df_dropped[['sales_usd','sales_currency']].groupby([df_dropped.time_code.dt.year,df_dropped.month]).sum().plot()\r\n",
    "plt.title('Total value of Sale over the months: ', fontsize='small')\r\n",
    "plt.xlabel('Year-Month', fontsize='small')\r\n",
    "plt.ylabel('Sum of Sale', fontsize='small')\r\n",
    "plt.tick_params(labelsize='small')\r\n",
    "\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [30, 10]\r\n",
    "plt.style.use('Solarize_Light2')\r\n",
    "\r\n",
    "legend=[]\r\n",
    "for x in df_join.time_code.dt.year.unique():\r\n",
    "    tmp=df_join[df_join.time_code.dt.year ==x]\r\n",
    "    for y in tmp.time_code.dt.month.unique():\r\n",
    "        legend.append((x,y))\r\n",
    "array=df_join.columns\r\n",
    "print(legend)\r\n",
    "for focus in array:\r\n",
    "    if focus != 'time_code' and focus != 'year'and focus != 'id_ram'and focus != 'month'and focus != 'week' and focus != \"sales_usd\" and focus != \"sales_currency\" and focus != \"currency\" :\r\n",
    "        if focus == 'continent':\r\n",
    "            max_val=3\r\n",
    "        else:\r\n",
    "            max_val=5\r\n",
    "        \r\n",
    "        print(\"PLOTTING FOR: \"+focus)\r\n",
    "\r\n",
    "        plt.figure(figsize=(20, 5))\r\n",
    "        tmp1=df_join.groupby(focus)[focus].count()\r\n",
    "        tmp1=tmp1.sort_values(ascending=False)\r\n",
    "        test=tmp1.index.values.tolist()\r\n",
    "        plt.title(\"Distribution of \"+focus)\r\n",
    "        plt.xlim([0,len(legend)])\r\n",
    "        plt.xlabel(\"Year and month\")\r\n",
    "        plt.ylabel(\"Sales\")\r\n",
    "       \r\n",
    "        plt.xticks(np.arange(len(legend)),legend)\r\n",
    "        plt.tick_params(labelrotation=90, labelsize='small')\r\n",
    "\r\n",
    "        #print('legend len:'+str(len(legend)))\r\n",
    "\r\n",
    "        for x in test[0:max_val]:\r\n",
    "            tmp=df_join[df_join[focus]==x]\r\n",
    "            #tmp.groupby([df_join.year, df_join.month])[focus].count().plot()\r\n",
    "            tmp2=tmp.groupby([df_join.time_code.dt.year, df_join.month])[focus].count().reset_index(name='count')\r\n",
    "            minyear=tmp2.time_code.min()\r\n",
    "            minmonth=tmp2[tmp2.time_code==minyear]\r\n",
    "            minmonth=minmonth.month.min()\r\n",
    "            index=(minyear,minmonth)\r\n",
    "            num_index=legend.index(index)\r\n",
    "            values=tmp.groupby([df_join.time_code.dt.year, df_join.month])[focus].count().values.tolist()\r\n",
    "            #print(values)\r\n",
    "            #print(num_index)\r\n",
    "            plt.plot(np.arange(num_index,len(values)+num_index),values)\r\n",
    "            #print(len(tmp.groupby([df_join.year, df_join.month])[focus].count().values.tolist()))\r\n",
    "\r\n",
    "        plt.legend(test[0:max_val])\r\n",
    "        plt.show()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine the data quality/accuracy\t\r\n",
    "- explanation on how treat outliers\r\n",
    "- quality/accuracy of attributes\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form of aggregation\t\r\n",
    "- reduction/sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Reduction of attributes, Some removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.drop(['month'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discretization & binarization\t(maybe move at the begin of clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute transformation\tlogaritmic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-PCA\r\n",
    " siccome droppo gli attributi categorici allora mi resta solo sales currency come numerico (o al massimo conversion rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------PCA \r\n",
    "df_num = df_dropped.drop(columns=cat)\r\n",
    "df_temp = df_num.sample(5000)\r\n",
    "df_temp = StandardScaler().fit_transform(df_temp)\r\n",
    "pca = PCA(n_components=1)\r\n",
    "x_pca = pca.fit_transform(df_temp)\r\n",
    "\r\n",
    "print(\"original shape: \", df_temp.shape)\r\n",
    "print(\"transformed shape:\", x_pca.shape)\r\n",
    "\r\n",
    "x_new = pca.inverse_transform(x_pca)\r\n",
    "\r\n",
    "plt.figure(figsize = (15,7))\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.scatter(df_temp[:, 0], df_temp[:, 1], alpha=0.2, s=20, c=\"r\")\r\n",
    "plt.scatter(x_new[:, 0], x_new[:, 1] , s=20, alpha=0.8, c=\"b\")  \r\n",
    "plt.title(\"PCA\")\r\n",
    "plt.xlabel(\"1st eigenvector\")\r\n",
    "plt.ylabel(\"2nd eigenvector\")\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(pca.explained_variance_ratio_)\r\n",
    "\"\"\"By using the attribute explained_variance_ratio_, \r\n",
    "you can see that the first principal component contains 72.77% of the variance\r\n",
    " and the second principal component contains 23.03% of the variance. \r\n",
    " Together, the two components contain 95.80% of the information.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\r\n",
    "possible transformation::\r\n",
    "- aggiungo tasso di cambio per capire come sono variati i prezzi in base alla fluttuazione della valuta\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_conversion=[]\r\n",
    "tmp1=df_dropped.sales_usd.tolist()\r\n",
    "tmp2=df_dropped.sales_currency.tolist()\r\n",
    "for index,x in enumerate(tmp1):\r\n",
    "    price_conversion.append(x/tmp2[index])\r\n",
    "df_dropped['conversion_rate']=price_conversion\r\n",
    "df_dropped[\"conversion_rate\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.drop([\"sales_currency\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend=[]\r\n",
    "for x in df_join.time_code.dt.year.unique():\r\n",
    "    tmp=df_join[df_join.time_code.dt.year ==x]\r\n",
    "    for y in tmp.time_code.dt.month.unique():\r\n",
    "        legend.append((x,y))\r\n",
    "\r\n",
    "focus='conversion_rate'\r\n",
    "print(\"PLOTTING FOR: \"+focus)\r\n",
    "\r\n",
    "plt.style.use('Solarize_Light2')\r\n",
    "test=df_dropped.currency.unique()\r\n",
    "#print(test)\r\n",
    "plt.title(\"Distribution of \"+focus)\r\n",
    "plt.xlim([0,len(legend)])\r\n",
    "plt.xlabel(\"Year and month\")\r\n",
    "plt.ylabel(\"Conversion Rate \")\r\n",
    "\r\n",
    "plt.xticks(np.arange(len(legend)),legend)\r\n",
    "plt.tick_params(labelrotation=90, labelsize='small')\r\n",
    "\r\n",
    "#print('legend len:'+str(len(legend)))\r\n",
    "\r\n",
    "for x in test:\r\n",
    "    tmp=df_dropped[df_dropped['currency']==x]\r\n",
    "    #tmp.groupby([df_dropped.year, df_dropped.month])[focus].count().plot()\r\n",
    "    tmp2=tmp.groupby([df_dropped.time_code.dt.year, df_dropped.month]).mean()\r\n",
    "    minyear=tmp2.index.get_level_values('time_code').min()\r\n",
    "    minmonth=tmp2[tmp2.index.get_level_values('time_code')==minyear]\r\n",
    "    minmonth=minmonth.index.get_level_values('month').min()\r\n",
    "    index=(minyear,minmonth)\r\n",
    "    num_index=legend.index(index)\r\n",
    "    values=tmp2['conversion_rate'].tolist()\r\n",
    "    #print(values)\r\n",
    "    #print(num_index)\r\n",
    "    plt.plot(np.arange(num_index,len(values)+num_index),values)\r\n",
    "    #print(len(tmp.groupby([df_dropped.year, df_dropped.month])[focus].count().values.tolist()))\r\n",
    "    \r\n",
    "print_legend=[]\r\n",
    "for x in test:\r\n",
    "    print_legend.append('USD/'+x)\r\n",
    "plt.legend(print_legend)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset/Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BY VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VENDORs = df_dropped['vendor'].unique()\r\n",
    "vs = pd.DataFrame(VENDORs)\r\n",
    "vs.set_index(0, inplace=True)\r\n",
    "vs.index.names = ['vendor']\r\n",
    "\r\n",
    "vs_cat = vs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total money for each continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df_dropped[df_dropped.continent==\"Europe\"].groupby(df_dropped.vendor)['sales_usd'].count()\r\n",
    "vs['sales_Europe']=test\r\n",
    "vs['sales_Europe'] = vs['sales_Europe'].fillna(0)\r\n",
    "\r\n",
    "test=df_dropped[df_dropped.continent==\"Oceania\"].groupby(df_dropped.vendor)['sales_usd'].count()\r\n",
    "vs['sales_Oceania']=test\r\n",
    "vs['sales_Oceania'] = vs['sales_Oceania'].fillna(0)\r\n",
    "\r\n",
    "test=df_dropped[df_dropped.continent==\"America\"].groupby(df_dropped.vendor)['sales_usd'].count()\r\n",
    "vs['sales_America']=test\r\n",
    "vs['sales_America'] = vs['sales_America'].fillna(0)\r\n",
    "\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I: total number of ram (id_ram) purchased by each vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = df_dropped.groupby(df_dropped['vendor'])[\"id_ram\"].count()\r\n",
    "\r\n",
    "I = pd.DataFrame(I)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['I'] = I[\"id_ram\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iu: number of distinct items purchased by the vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iu = df_dropped.groupby(df_dropped['vendor'])[\"id_ram\"].nunique()\r\n",
    "\r\n",
    "Iu = pd.DataFrame(Iu)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['Iu'] = Iu[\"id_ram\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imax: maximum number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imax = df_dropped.groupby(['vendor', \"time_code\"])[\"id_ram\"].count().max(level=\"vendor\")\r\n",
    "\r\n",
    "\"\"\"for x in df_dropped[\"time_code\"].unique():\r\n",
    "    df_temp = df_dropped[(df_dropped[\"vendor\"]==\"ARLT\") & (df_dropped[\"time_code\"]==x)]\r\n",
    "    if len(df_temp) > 45:\r\n",
    "        print(df_temp)\r\n",
    "        print()\r\n",
    "        print(df_temp.describe())\"\"\"\r\n",
    "\r\n",
    "#print(Imax)\r\n",
    "Imax = pd.DataFrame(Imax)\r\n",
    "\r\n",
    "#print(Imax)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Imax'] = Imax[\"id_ram\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imin: minimum number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imin = df_dropped.groupby(['vendor', \"time_code\"])[\"id_ram\"].count().min(level=\"vendor\")\r\n",
    "\r\n",
    "\"\"\"for x in df_dropped[\"time_code\"].unique():\r\n",
    "    df_temp = df_dropped[(df_dropped[\"vendor\"]==\"ARLT\") & (df_dropped[\"time_code\"]==x)]\r\n",
    "    if len(df_temp) > 45:\r\n",
    "        print(df_temp)\r\n",
    "        print()\r\n",
    "        print(df_temp.describe())\"\"\"\r\n",
    "\r\n",
    "#print(Imax)\r\n",
    "Imin = pd.DataFrame(Imin)\r\n",
    "\r\n",
    "#print(Imin)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Imin'] = Imin[\"id_ram\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iavg: average number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iavg = df_dropped.groupby(['vendor', \"time_code\"])[\"id_ram\"].count().mean(level=\"vendor\")\r\n",
    "\r\n",
    "#print(Iavg)\r\n",
    "Iavg = pd.DataFrame(Iavg)\r\n",
    "\r\n",
    "#print(Iavg)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Iavg'] = Iavg[\"id_ram\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ep: Shannon's Entropy on the types of products purchased by the vendor (id_ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shannon entropy on the purchasing behaviour of the customer\r\n",
    "def estimate_shannon_entropy(values):\r\n",
    "    m = len(values)\r\n",
    "    IDs = collections.Counter([value for value in values])\r\n",
    "    shannon_entropy_value = 0\r\n",
    "    for ID in IDs:\r\n",
    "        # number of residues\r\n",
    "        n_i = IDs[ID]\r\n",
    "        # n_i (# residues type i) / M (# residues in column)\r\n",
    "        p_i = n_i / float(m)\r\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\r\n",
    "        shannon_entropy_value += entropy_i\r\n",
    "    if shannon_entropy_value == 0:\r\n",
    "        return 0\r\n",
    "    return shannon_entropy_value * -1\r\n",
    "\r\n",
    "Ep = df_dropped.groupby('vendor')[\"id_ram\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Ep)\r\n",
    "# create dataframe\r\n",
    "Ep = pd.DataFrame(Ep)\r\n",
    "\r\n",
    "#print(Ep)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Ep'] = Ep\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eb: Shannon's Entropy on the frequency and extent of the vendor's shopping sessions (time_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb = df_dropped.groupby('vendor')[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Eb)\r\n",
    "# create dataframe\r\n",
    "Eb = pd.DataFrame(Eb)\r\n",
    "\r\n",
    "#print(Eb)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Eb'] = Eb\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ew: Shannon's Entropy on the weekday of the vendor's purchases (time_code.dt.day_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ew = df_dropped.copy()\r\n",
    "Ew['time_code'] = Ew.time_code.dt.day_name(locale = 'English')\r\n",
    "Ew = Ew.groupby('vendor')[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Ew)\r\n",
    "# create dataframe\r\n",
    "Ew = pd.DataFrame(Ew)\r\n",
    "\r\n",
    "#print(Ew)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Ew'] = Ew\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Em: Shannon's Entropy on the month of the vendor's purchases (time_code.dt.month_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Em = df_dropped.copy()\r\n",
    "Em['time_code'] = Em.time_code.dt.month_name(locale = 'English')\r\n",
    "Em = Em.groupby('vendor')[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Em)\r\n",
    "# create dataframe\r\n",
    "Em = pd.DataFrame(Em)\r\n",
    "\r\n",
    "#print(Em)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Em'] = Em\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stot: total amount spent by each vendor (USD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stot = df_join.groupby('vendor')[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "#print(Stot)\r\n",
    "Stot = pd.DataFrame(Stot)\r\n",
    "\r\n",
    "#print(Stot)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Stot_USD'] = Stot[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smax: Maximum amout spent by each vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Smax = df_dropped.groupby(['vendor', \"time_code\"])[\"sales_usd\"].sum().max(level=\"vendor\")\r\n",
    "\r\n",
    "#print(Smax)\r\n",
    "Smax = pd.DataFrame(Smax)\r\n",
    "\r\n",
    "#print(Smax)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Smax_USD'] = Smax[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Savg: average amount spent by each vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Savg = df_dropped.groupby(['vendor', \"time_code\"])[\"sales_usd\"].sum().mean(level=\"vendor\")\r\n",
    "\r\n",
    "#print(Savg)\r\n",
    "Savg = pd.DataFrame(Savg)\r\n",
    "\r\n",
    "#print(Savg)\r\n",
    "# add column to the new dataset\r\n",
    "vs['Savg_USD'] = Savg[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWmax: Maximum amout spent by each vendor within a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWmax = df_dropped.groupby(['vendor', df_dropped[\"time_code\"].dt.week])[\"sales_usd\"].sum().max(level=\"vendor\")\r\n",
    "\r\n",
    "#print(SWmax)\r\n",
    "SWmax = pd.DataFrame(SWmax)\r\n",
    "\r\n",
    "#print(SWmax)\r\n",
    "# add column to the new dataset\r\n",
    "vs['SWmax_USD'] = SWmax[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWavg: Average amount spent by each vendor within a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWavg = df_dropped.groupby(['vendor', df_dropped[\"time_code\"].dt.week])[\"sales_usd\"].sum().mean(level=\"vendor\")\r\n",
    "\r\n",
    "#print(SWavg)\r\n",
    "SWavg = pd.DataFrame(SWavg)\r\n",
    "\r\n",
    "#print(SWavg)\r\n",
    "# add column to the new dataset\r\n",
    "vs['SWavg_USD'] = SWavg[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMmax: Maximum amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMmax = df_dropped.groupby(['vendor', df_dropped.time_code.dt.month])[\"sales_usd\"].sum().max(level=\"vendor\")\r\n",
    "\r\n",
    "#print(SMmax)\r\n",
    "SMmax = pd.DataFrame(SMmax)\r\n",
    "\r\n",
    "#print(SMmax)\r\n",
    "# add column to the new dataset\r\n",
    "vs['SMmax_USD'] = SMmax[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMavg: Average amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMavg = df_dropped.groupby(['vendor', df_dropped.time_code.dt.month])[\"sales_usd\"].sum().mean(level=\"vendor\")\r\n",
    "\r\n",
    "#print(SMavg)\r\n",
    "SMavg = pd.DataFrame(SMavg)\r\n",
    "\r\n",
    "#print(SMavg)\r\n",
    "# add column to the new dataset\r\n",
    "vs['SMavg_USD'] = SMavg[\"sales_usd\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSess: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSess = df_dropped.groupby('vendor')[\"time_code\"].nunique()\r\n",
    "\r\n",
    "#print(NSess)\r\n",
    "NSess = pd.DataFrame(NSess)\r\n",
    "\r\n",
    "#print(NSess)\r\n",
    "# add column to the new dataset\r\n",
    "vs['NSess'] = NSess[\"time_code\"]\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cont_Max: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cont_Max = df_dropped.groupby(df_dropped['vendor'])[\"continent\"].nunique()\r\n",
    "\r\n",
    "Cont_Max = pd.DataFrame(Cont_Max)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['Cont_Max'] = Cont_Max[\"continent\"]\r\n",
    "vs['Cont_Max'] = vs['Cont_Max'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim_unik = df_dropped.groupby(df_dropped['vendor'])[\"memory_dim\"].nunique()\r\n",
    "\r\n",
    "Dim_unik = pd.DataFrame(Dim_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['Dim_unik'] = Dim_unik[\"memory_dim\"]\r\n",
    "vs['Dim_unik'] = vs['Dim_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_unik = df_dropped.groupby(df_dropped['vendor'])[\"memory_type\"].nunique()\r\n",
    "\r\n",
    "Type_unik = pd.DataFrame(Type_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['Type_unik'] = Type_unik[\"memory_type\"]\r\n",
    "vs['Type_unik'] = vs['Type_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clok_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clok_unik = df_dropped.groupby(df_dropped['vendor'])[\"clock\"].nunique()\r\n",
    "\r\n",
    "clok_unik = pd.DataFrame(clok_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['clok_unik'] = clok_unik[\"clock\"]\r\n",
    "vs['clok_unik'] = vs['clok_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coun_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coun_unik = df_dropped.groupby(df_dropped['vendor'])[\"country\"].nunique()\r\n",
    "\r\n",
    "coun_unik = pd.DataFrame(coun_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['coun_unik'] = coun_unik[\"country\"]\r\n",
    "vs['coun_unik'] = vs['coun_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_unik = df_dropped.groupby(df_dropped['vendor'])[\"region\"].nunique()\r\n",
    "\r\n",
    "reg_unik = pd.DataFrame(reg_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['reg_unik'] = reg_unik[\"region\"]\r\n",
    "vs['reg_unik'] = vs['reg_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### day_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_day = df_dropped.copy()\r\n",
    "df_with_day['time_code'] = df_with_day.time_code.dt.day\r\n",
    "\r\n",
    "day_unik = df_with_day.groupby(df_with_day['vendor'])[\"time_code\"].nunique()\r\n",
    "\r\n",
    "day_unik = pd.DataFrame(day_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['day_unik'] = day_unik[\"time_code\"]\r\n",
    "vs['day_unik'] = vs['day_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### week_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_week = df_dropped.copy()\r\n",
    "df_with_week['time_code'] = df_with_week.time_code.dt.week\r\n",
    "\r\n",
    "week_unik = df_with_week.groupby(df_with_week['vendor'])[\"time_code\"].nunique()\r\n",
    "\r\n",
    "week_unik = pd.DataFrame(week_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['week_unik'] = week_unik[\"time_code\"]\r\n",
    "vs['week_unik'] = vs['week_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_unik = df_dropped.groupby(df_dropped['vendor'])[\"sales_usd\"].nunique()\r\n",
    "\r\n",
    "price_unik = pd.DataFrame(price_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['price_unik'] = price_unik[\"sales_usd\"]\r\n",
    "vs['price_unik'] = vs['price_unik'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rate_avg: Average amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rate_avg = df_dropped.groupby(df_dropped['vendor'])[\"conversion_rate\"].mean()\r\n",
    "\r\n",
    "Rate_avg = pd.DataFrame(Rate_avg)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs['Rate_avg'] = Rate_avg\r\n",
    "vs['Rate_avg'] = vs['Rate_avg'].fillna(0)\r\n",
    "\r\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Country: Country associated with the majority of the vendor's transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country = df_dropped.groupby('vendor').country.unique()\r\n",
    "\r\n",
    "print(Country[0])\r\n",
    "print(Country[1])\r\n",
    "print(Country)\r\n",
    "# create dataframe\r\n",
    "Country = pd.DataFrame(Country.apply(lambda x: x[0]))\r\n",
    "\r\n",
    "print(Country)\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Country'] = Country\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fav_weekday: day of the week during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_day_week = df_dropped.copy()\r\n",
    "df_with_day_week['time_code'] = df_with_day_week.time_code.dt.day_name(locale = 'English')\r\n",
    "\r\n",
    "spent_per_day_week = df_with_day_week.groupby(['vendor', 'time_code']).sales_usd.sum()\r\n",
    "Fav_weekday = {}\r\n",
    "for row in spent_per_day_week.iteritems():\r\n",
    "    if row[0][0] not in Fav_weekday:\r\n",
    "        Fav_weekday[row[0][0]] = row[0][1]\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav_weekday = pd.DataFrame.from_dict(Fav_weekday, orient='index')\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Fav_weekday'] = Fav_weekday\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_month: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_months = df_dropped.copy()\r\n",
    "df_with_months['time_code'] = df_with_months.time_code.dt.month_name(locale = 'English')\r\n",
    "\r\n",
    "spent_per_month = df_with_months.groupby(['vendor', 'time_code']).sales_usd.sum()\r\n",
    "Fav_month = {}\r\n",
    "for row in spent_per_month.iteritems():\r\n",
    "    if row[0][0] not in Fav_month:\r\n",
    "        Fav_month[row[0][0]] = row[0][1]\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav_month = pd.DataFrame.from_dict(Fav_month, orient='index')\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Fav_month'] = Fav_month\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_dim: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_dim = df_dropped.groupby(['vendor', 'memory_dim'])['memory_dim'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_dim.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_dim.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]                            \r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_dim'] = Fav\r\n",
    "vs_cat['fav_dim'] = vs_cat['fav_dim'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_dim = df_dropped.groupby(['vendor', 'memory_type'])['memory_type'].count().reset_index(name=\"count\")\r\n",
    "tmp = fav_dim[fav_dim[\"vendor\"]==\"geizhals_unknown\"]\r\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_price: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_price = df_dropped.groupby(['vendor', 'sales_usd'])['sales_usd'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_price.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_price.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]    \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_price'] = Fav\r\n",
    "vs_cat['fav_price'] = vs_cat['fav_price'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_model: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_model = df_dropped.groupby(['vendor', 'ram_model'])['ram_model'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_model.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_model.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_model'] = Fav\r\n",
    "vs_cat['fav_model'] = vs_cat['fav_model'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_mem_type: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_mem_type = df_dropped.groupby(['vendor', 'memory_type'])['memory_type'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_mem_type.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_mem_type.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_mem_type'] = Fav\r\n",
    "vs_cat['fav_mem_type'] = vs_cat['fav_mem_type'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_clock: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_clock = df_dropped.groupby(['vendor', 'clock'])['clock'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_clock.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_clock.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_clock'] = Fav\r\n",
    "vs_cat['fav_clock'] = vs_cat['fav_clock'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_continent: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_continent = df_dropped.groupby(['vendor', 'continent'])['continent'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_continent.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_continent.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_continent'] = Fav\r\n",
    "vs_cat['fav_continent'] = vs_cat['fav_continent'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_region: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_region = df_dropped.groupby(['vendor', 'region'])['region'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_region.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_region.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_region'] = Fav\r\n",
    "vs_cat['fav_region'] = vs_cat['fav_region'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_most: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_most = df_dropped.groupby(['vendor', 'conversion_rate'])['conversion_rate'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in Conv_most.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in Conv_most.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Conv_most'] = Fav\r\n",
    "vs_cat['Conv_most'] = vs_cat['Conv_most'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_less: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_less = df_dropped.groupby(['vendor', 'conversion_rate'])['conversion_rate'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in Conv_less.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in Conv_less.iteritems():\r\n",
    "            if tmp > y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Conv_less'] = Fav\r\n",
    "vs_cat['Conv_less'] = vs_cat['Conv_less'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_max: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_max = df_dropped.groupby('vendor')[\"conversion_rate\"].max()\r\n",
    "\r\n",
    "Conv_max = pd.DataFrame(Conv_max)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Conv_max'] = Conv_max\r\n",
    "vs_cat['Conv_max'] = vs_cat['Conv_max'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_min: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_min = df_dropped.groupby('vendor')[\"conversion_rate\"].min()\r\n",
    "\r\n",
    "Conv_min = pd.DataFrame(Conv_min)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['Conv_min'] = Conv_min\r\n",
    "vs_cat['Conv_min'] = vs_cat['Conv_min'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_week: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_week = df_dropped.copy()\r\n",
    "df_with_week['time_code'] = df_with_week.time_code.dt.week\r\n",
    "\r\n",
    "fav_week = df_with_week.groupby(['vendor', \"time_code\"]).time_code.count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_week.iteritems():\r\n",
    "    if x[0][0] not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[x[0][0]] = x[0][1]\r\n",
    "        for y in fav_week.iteritems():\r\n",
    "            if tmp > y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    tmp = y[1]\r\n",
    "                    Fav[y[0][0]] = y[0][1]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "vs_cat['fav_week'] = Fav\r\n",
    "vs_cat['fav_week'] = vs_cat['fav_week'].fillna(0)\r\n",
    "\r\n",
    "print(vs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics on the Vendor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = vs[(vs.I != 0)]\r\n",
    "vs_cat = vs_cat[(vs_cat.fav_continent != 0)]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats on new dataset XXX\r\n",
    "print(vs.describe())\r\n",
    "print()\r\n",
    "print(vs_cat.describe())\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data distribution\r\n",
    "mpl.rc('figure', max_open_warning = 0)\r\n",
    "sturge_number = math.trunc(np.log2(len(vs)))\r\n",
    "for col in vs:  \r\n",
    "    print(\"\\n\\nCONSIDERATIONS ABOUT THE ATTRIBUTE: \" + col)\r\n",
    "    vs[col].hist(bins = sturge_number + 1)  #Sturges' rule\r\n",
    "    pl.suptitle(col)    \r\n",
    "    #plt.savefig(dir+'\\\\Histogram\\\\'+col+'-hist.jpg')\r\n",
    "    plt.xticks(rotation=45)\r\n",
    "    plt.figure(figsize = (10,8))\r\n",
    "    plt.show()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization on categorical\r\n",
    "for x in vs_cat:  \r\n",
    "    plt.bar(vs_cat[x].unique(),vs_cat[x].value_counts())\r\n",
    "    plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "    plt.title(\"Distribution of \" + x)\r\n",
    "    plt.xlabel(x)\r\n",
    "    plt.ylabel(\"Number of customers\")\r\n",
    "    plt.show()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1= vs.copy()\r\n",
    "tmp2= vs_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\r\n",
    "for col in vs:  \r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    ax.set_title('\\nOutliers of ' +col+ ' in the Dataset')\r\n",
    "    ax.boxplot(vs[col])\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    print(\"---------------------------------------------------------------\")\r\n",
    "    \r\n",
    "def iqr_values(s):\r\n",
    "    q1 = s.quantile(q = 0.25)\r\n",
    "\r\n",
    "    q3 = s.quantile(q = 0.75)    \r\n",
    "\r\n",
    "    iqr = q3 - q1\r\n",
    "\r\n",
    "    iqr_left = q1 - 3*iqr\r\n",
    "    \r\n",
    "    iqr_right = q3 + 3*iqr\r\n",
    "    \r\n",
    "    return iqr_left, iqr_right\r\n",
    "\r\n",
    "\r\n",
    "for x in vs:\r\n",
    "    if (x != \"Imin\") & (x != \"coun_unik\"):\r\n",
    "        print(\"OUTLIERS REPRESENTATION FOR ATTRIBUTE :\\t\" + x)\r\n",
    "        left_sale, right_sale = iqr_values(vs[x])\r\n",
    "        vs[(vs[x] > left_sale) & (vs[x] < right_sale)][x].plot.box()\r\n",
    "        plt.show()\r\n",
    "        print()\r\n",
    "        outliers = vs[(vs[x] < left_sale) | (vs[x] > right_sale)]\r\n",
    "        print(\"\\n Outliers founded\")\r\n",
    "        print()\r\n",
    "        print(outliers.describe())\r\n",
    "        print()\r\n",
    "        outliers.drop_duplicates(inplace=True)\r\n",
    "        print(\"--------------------------------------------------\")\r\n",
    "        print(\"\\n Dataset dropped\")\r\n",
    "        #vs_dropped[x] = vs[x][(vs[x] > left_sale) & (vs[x] < right_sale)]\r\n",
    "        vs.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "        vs_cat.drop(outliers.index, inplace=True)\r\n",
    "        print(vs.describe())\r\n",
    "        print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCorrelation Matrix with Spearman::\")\r\n",
    "corr = vs.corr(method='spearman')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "# correlation\r\n",
    "print(\"\\nCorrelation Matrix with Pearson::\")\r\n",
    "#plt.rc('figure', figsize=(18, 7))\r\n",
    "corr = vs.corr(method='pearson')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\nHeatmap correlation::\")\r\n",
    "sns.heatmap(vs.corr(), annot=True);\r\n",
    "\r\n",
    "\"\"\"for x in vs:\r\n",
    "    for y in vs:\r\n",
    "        if x != y:\r\n",
    "            plt.figure(figsize = (15,15))\r\n",
    "            plt.scatter(vs[x], vs[y])\r\n",
    "            plt.xlabel(x)\r\n",
    "            plt.ylabel(y)\r\n",
    "            plt.title('\\nCorrelation between ' + x + ' and ' + y + ' in vs')\r\n",
    "            plt.show()\"\"\"\r\n",
    "\r\n",
    "#---- maintain attributes below a certain threshold\r\n",
    "high_corr = []\r\n",
    "print(high_corr)\r\n",
    "threshold = 0.80\r\n",
    "list_corr = list(corr.to_numpy())\r\n",
    "ext_ind = 0\r\n",
    "for i in list_corr:\r\n",
    "    int_ind = 0\r\n",
    "    for j in i:\r\n",
    "        if j > threshold and int_ind != ext_ind:\r\n",
    "            high_corr.append(int_ind)\r\n",
    "        int_ind += 1\r\n",
    "    ext_ind += 1\r\n",
    "print(\"Attributes above threshold of \" + str(threshold) + \" are:\\n\")\r\n",
    "print(list(vs.columns[high_corr]))\r\n",
    "\r\n",
    "\r\n",
    "vs.drop(columns=list(vs.columns[high_corr]), inplace=True, axis=1)\r\n",
    "\r\n",
    "# correlation\r\n",
    "print(\"\\nCorrelation Matrix with Pearson::\")\r\n",
    "corr = vs.corr(method='pearson')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs = tmp1.copy()\r\n",
    "#vs_cat = tmp2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BY BRAND & VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multind=pd.MultiIndex.from_product([df_dropped.vendor.unique().tolist(),  df_dropped.brand.unique().tolist()])\r\n",
    "bvs = pd.DataFrame(index = multind, columns = ['Total_gain'])\r\n",
    "bvs_cat = bvs.copy()\r\n",
    "bvs_cat.drop(labels='Total_gain', inplace=True, axis=1)\r\n",
    "\r\n",
    "test=df_join.groupby([df_dropped.vendor,df_dropped.brand])['sales_usd'].sum()\r\n",
    "bvs['Total_gain']=test\r\n",
    "bvs['Total_gain'] = bvs['Total_gain'].fillna(0)\r\n",
    "\"\"\"bvs.set_index(0, inplace=True)\r\n",
    "vs.index.names = ['vendor']\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total money for each continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df_dropped[df_dropped.continent==\"Europe\"].groupby([df_dropped.vendor,df_dropped.brand])['sales_usd'].count()\r\n",
    "bvs['sales_Europe']=test\r\n",
    "bvs['sales_Europe'] = bvs['sales_Europe'].fillna(0)\r\n",
    "\r\n",
    "test=df_dropped[df_dropped.continent==\"Oceania\"].groupby([df_dropped.vendor,df_dropped.brand])['sales_usd'].count()\r\n",
    "bvs['sales_Oceania']=test\r\n",
    "bvs['sales_Oceania'] = bvs['sales_Oceania'].fillna(0)\r\n",
    "\r\n",
    "test=df_dropped[df_dropped.continent==\"America\"].groupby([df_dropped.vendor,df_dropped.brand])['sales_usd'].count()\r\n",
    "bvs['sales_America']=test\r\n",
    "bvs['sales_America'] = bvs['sales_America'].fillna(0)\r\n",
    "\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I: total number of ram (id_ram) purchased by each vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"id_ram\"].count()\r\n",
    "\r\n",
    "I = pd.DataFrame(I)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['I'] = I[\"id_ram\"]\r\n",
    "bvs['I'] = bvs['I'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iu: number of distinct items purchased by the vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iu = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"id_ram\"].nunique()\r\n",
    "\r\n",
    "Iu = pd.DataFrame(Iu)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Iu'] = Iu[\"id_ram\"]\r\n",
    "bvs['Iu'] = bvs['Iu'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imax: maximum number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imax = df_dropped.groupby(['vendor', \"brand\", \"time_code\"])[\"id_ram\"].count()\r\n",
    "\r\n",
    "Imax_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: Imax_list.append(Imax.loc[vendor,brand].max())\r\n",
    "        except: Imax_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Imax'] = Imax_list\r\n",
    "bvs['Imax'] = bvs['Imax'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imin: minimum number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imin = df_dropped.groupby(['vendor', \"brand\", \"time_code\"])[\"id_ram\"].count()\r\n",
    "\r\n",
    "Imin_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: Imin_list.append(Imin.loc[vendor,brand].min())\r\n",
    "        except: Imin_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Imin'] = Imin_list\r\n",
    "bvs['Imin'] = bvs['Imin'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iavg: average number of items purchased by the vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iavg = df_dropped.groupby(['vendor', \"brand\", \"time_code\"])[\"id_ram\"].count()\r\n",
    "\r\n",
    "Iavg_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: Iavg_list.append(Iavg.loc[vendor,brand].mean())\r\n",
    "        except: Iavg_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Iavg'] = Iavg_list\r\n",
    "bvs['Iavg'] = bvs['Iavg'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ep: Shannon's Entropy on the types of products purchased by the vendor (id_ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shannon entropy on the purchasing behaviour of the customer\r\n",
    "def estimate_shannon_entropy(values):\r\n",
    "    m = len(values)\r\n",
    "    IDs = collections.Counter([value for value in values])\r\n",
    "    shannon_entropy_value = 0\r\n",
    "    for ID in IDs:\r\n",
    "        # number of residues\r\n",
    "        n_i = IDs[ID]\r\n",
    "        # n_i (# residues type i) / M (# residues in column)\r\n",
    "        p_i = n_i / float(m)\r\n",
    "        entropy_i = p_i * (math.log(p_i, 2))\r\n",
    "        shannon_entropy_value += entropy_i\r\n",
    "    if shannon_entropy_value == 0:\r\n",
    "        return 0\r\n",
    "    return shannon_entropy_value * -1\r\n",
    "\r\n",
    "Ep = df_dropped.groupby(['vendor', \"brand\"])[\"id_ram\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Ep)\r\n",
    "# create dataframe\r\n",
    "Ep = pd.DataFrame(Ep)\r\n",
    "\r\n",
    "#print(Ep)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Ep'] = Ep\r\n",
    "bvs['Ep'] = bvs['Ep'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eb: Shannon's Entropy on the frequency and extent of the vendor's shopping sessions (time_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eb = df_dropped.groupby(['vendor', \"brand\"])[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Eb)\r\n",
    "# create dataframe\r\n",
    "Eb = pd.DataFrame(Eb)\r\n",
    "\r\n",
    "#print(Eb)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Eb'] = Eb\r\n",
    "bvs['Eb'] = bvs['Eb'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ew: Shannon's Entropy on the weekday of the vendor's purchases (time_code.dt.day_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ew = df_dropped.copy()\r\n",
    "Ew['time_code'] = Ew.time_code.dt.day_name(locale = 'English')\r\n",
    "Ew = Ew.groupby(['vendor', \"brand\"])[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Ew)\r\n",
    "# create dataframe\r\n",
    "Ew = pd.DataFrame(Ew)\r\n",
    "\r\n",
    "#print(Ew)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Ew'] = Ew\r\n",
    "bvs['Ew'] = bvs['Ew'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Em: Shannon's Entropy on the month of the vendor's purchases (time_code.dt.month_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Em = df_dropped.copy()\r\n",
    "Em['time_code'] = Em.time_code.dt.month_name(locale = 'English')\r\n",
    "Em = Em.groupby(['vendor', \"brand\"])[\"time_code\"].apply(estimate_shannon_entropy)\r\n",
    "\r\n",
    "#print(Em)\r\n",
    "# create dataframe\r\n",
    "Em = pd.DataFrame(Em)\r\n",
    "\r\n",
    "#print(Em)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Em'] = Em\r\n",
    "bvs['Em'] = bvs['Em'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stot: total amount spent by each vendor (USD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stot = df_join.groupby(['vendor', \"brand\"])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "#print(Stot)\r\n",
    "Stot = pd.DataFrame(Stot)\r\n",
    "\r\n",
    "#print(Stot)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Stot_USD'] = Stot[\"sales_usd\"]\r\n",
    "bvs['Stot_USD'] = bvs['Stot_USD'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smax: Maximum amout spent by each vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Smax = df_dropped.groupby(['vendor', \"brand\", \"time_code\"])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "Smax_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: Smax_list.append(Smax.loc[vendor,brand].max())\r\n",
    "        except: Smax_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Smax'] = Smax_list\r\n",
    "bvs['Smax'] = bvs['Smax'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Savg: average amount spent by each vendor within a single shopping session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Savg = df_dropped.groupby(['vendor', \"brand\", \"time_code\"])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "Savg_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: Savg_list.append(Savg.loc[vendor,brand].mean())\r\n",
    "        except: Savg_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Savg'] = Savg_list\r\n",
    "bvs['Savg'] = bvs['Savg'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWmax: Maximum amout spent by each vendor within a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWmax = df_dropped.groupby(['vendor', \"brand\", df_dropped[\"time_code\"].dt.week])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "SWmax_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: SWmax_list.append(SWmax.loc[vendor,brand].max())\r\n",
    "        except: SWmax_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['SWmax'] = SWmax_list\r\n",
    "bvs['SWmax'] = bvs['SWmax'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SWavg: Average amount spent by each vendor within a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWavg = df_dropped.groupby(['vendor', \"brand\", df_dropped[\"time_code\"].dt.week])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "SWavg_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: SWavg_list.append(SWavg.loc[vendor,brand].mean())\r\n",
    "        except: SWavg_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['SWavg'] = SWavg_list\r\n",
    "bvs['SWavg'] = bvs['SWavg'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMmax: Maximum amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMmax = df_dropped.groupby(['vendor', \"brand\", df_dropped[\"time_code\"].dt.month])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "SMmax_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: SMmax_list.append(SMmax.loc[vendor,brand].max())\r\n",
    "        except: SMmax_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['SMmax'] = SMmax_list\r\n",
    "bvs['SMmax'] = bvs['SMmax'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMavg: Average amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMavg = df_dropped.groupby(['vendor', \"brand\", df_dropped[\"time_code\"].dt.month])[\"sales_usd\"].sum()\r\n",
    "\r\n",
    "SMavg_list = []\r\n",
    "for vendor in df_dropped.vendor.unique():\r\n",
    "    for brand in df_dropped.brand.unique():\r\n",
    "        try: SMavg_list.append(SMavg.loc[vendor,brand].mean())\r\n",
    "        except: SMavg_list.append(0)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['SMavg'] = SMavg_list\r\n",
    "bvs['SMavg'] = bvs['SMavg'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSess: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSess = df_dropped.groupby(['vendor', \"brand\"])[\"time_code\"].nunique()\r\n",
    "\r\n",
    "#print(NSess)\r\n",
    "NSess = pd.DataFrame(NSess)\r\n",
    "\r\n",
    "#print(NSess)\r\n",
    "# add column to the new dataset\r\n",
    "bvs['NSess'] = NSess[\"time_code\"]\r\n",
    "bvs['NSess'] = bvs['NSess'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cont_Max: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cont_Max = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"continent\"].nunique()\r\n",
    "\r\n",
    "Cont_Max = pd.DataFrame(Cont_Max)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Cont_Max'] = Cont_Max[\"continent\"]\r\n",
    "bvs['Cont_Max'] = bvs['Cont_Max'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dim_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dim_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"memory_dim\"].nunique()\r\n",
    "\r\n",
    "Dim_unik = pd.DataFrame(Dim_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Dim_unik'] = Dim_unik[\"memory_dim\"]\r\n",
    "bvs['Dim_unik'] = bvs['Dim_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"memory_type\"].nunique()\r\n",
    "\r\n",
    "Type_unik = pd.DataFrame(Type_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Type_unik'] = Type_unik[\"memory_type\"]\r\n",
    "bvs['Type_unik'] = bvs['Type_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clok_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clok_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"clock\"].nunique()\r\n",
    "\r\n",
    "clok_unik = pd.DataFrame(clok_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['clok_unik'] = clok_unik[\"clock\"]\r\n",
    "bvs['clok_unik'] = bvs['clok_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coun_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coun_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"country\"].nunique()\r\n",
    "\r\n",
    "coun_unik = pd.DataFrame(coun_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['coun_unik'] = coun_unik[\"country\"]\r\n",
    "bvs['coun_unik'] = bvs['coun_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"region\"].nunique()\r\n",
    "\r\n",
    "reg_unik = pd.DataFrame(reg_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['reg_unik'] = reg_unik[\"region\"]\r\n",
    "bvs['reg_unik'] = bvs['reg_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### day_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_day = df_dropped.copy()\r\n",
    "df_with_day['time_code'] = df_with_day.time_code.dt.day\r\n",
    "\r\n",
    "day_unik = df_with_day.groupby([df_with_day['vendor'], df_with_day['brand']])[\"time_code\"].nunique()\r\n",
    "\r\n",
    "day_unik = pd.DataFrame(day_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['day_unik'] = day_unik[\"time_code\"]\r\n",
    "bvs['day_unik'] = bvs['day_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### week_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_week = df_dropped.copy()\r\n",
    "df_with_week['time_code'] = df_with_week.time_code.dt.week\r\n",
    "\r\n",
    "week_unik = df_with_week.groupby([df_with_week['vendor'], df_with_week['brand']])[\"time_code\"].nunique()\r\n",
    "\r\n",
    "week_unik = pd.DataFrame(week_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['week_unik'] = week_unik[\"time_code\"]\r\n",
    "bvs['week_unik'] = bvs['week_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price_unik: number of shopping sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_unik = df_dropped.groupby([df_dropped['vendor'], df_dropped['brand']])[\"sales_usd\"].nunique()\r\n",
    "\r\n",
    "price_unik = pd.DataFrame(price_unik)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['price_unik'] = price_unik[\"sales_usd\"]\r\n",
    "bvs['price_unik'] = bvs['price_unik'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rate_avg: Average amout spent by each vendor within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rate_avg = df_dropped.groupby(['vendor', \"brand\"])[\"conversion_rate\"].mean()\r\n",
    "\r\n",
    "Rate_avg = pd.DataFrame(Rate_avg)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs['Rate_avg'] = Rate_avg\r\n",
    "bvs['Rate_avg'] = bvs['Rate_avg'].fillna(0)\r\n",
    "\r\n",
    "print(bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Country: Country associated with the majority of the vendor's transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_country = df_dropped.groupby(['vendor', \"brand\", 'country'])['country'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_country.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_country.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2]                            \r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_country'] = Fav\r\n",
    "bvs_cat['fav_country'] = bvs_cat['fav_country'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fav_weekday: day of the week during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_day_week = df_dropped.copy()\r\n",
    "df_with_day_week['time_code'] = df_with_day_week.time_code.dt.day_name(locale = 'English')\r\n",
    "\r\n",
    "spent_per_day_week = df_with_day_week.groupby(['vendor', \"brand\", 'time_code']).sales_usd.sum()\r\n",
    "Fav = {}\r\n",
    "for x in spent_per_day_week.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in spent_per_day_week.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Fav_weekday'] = Fav\r\n",
    "bvs_cat['Fav_weekday'] = bvs_cat['Fav_weekday'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_month: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_months = df_dropped.copy()\r\n",
    "df_with_months['time_code'] = df_with_months.time_code.dt.month_name(locale = 'English')\r\n",
    "\r\n",
    "spent_per_month = df_with_months.groupby(['vendor', \"brand\", 'time_code']).sales_usd.sum()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in spent_per_month.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in spent_per_month.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Fav_month'] = Fav\r\n",
    "bvs_cat['Fav_month'] = bvs_cat['Fav_month'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_dim: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_dim = df_dropped.groupby(['vendor', \"brand\", 'memory_dim'])['memory_dim'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_dim.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_dim.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2]                            \r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_dim'] = Fav\r\n",
    "bvs_cat['fav_dim'] = bvs_cat['fav_dim'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_dim = df_dropped.groupby(['vendor', \"brand\", 'memory_type'])['memory_type'].count().reset_index(name=\"count\")\r\n",
    "tmp = fav_dim[(fav_dim[\"vendor\"]==\"geizhals_unknown\") & (fav_dim[\"brand\"]==\"APACER\")]\r\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_price: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_price = df_dropped.groupby(['vendor', \"brand\", 'sales_usd'])['sales_usd'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_price.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_price.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_price'] = Fav\r\n",
    "bvs_cat['fav_price'] = bvs_cat['fav_price'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_model: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_model = df_dropped.groupby(['vendor', \"brand\", 'ram_model'])['ram_model'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_model.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_model.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_model'] = Fav\r\n",
    "bvs_cat['fav_model'] = bvs_cat['fav_model'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_mem_type: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_mem_type = df_dropped.groupby(['vendor', \"brand\", 'memory_type'])['memory_type'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_mem_type.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_mem_type.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_mem_type'] = Fav\r\n",
    "bvs_cat['fav_mem_type'] = bvs_cat['fav_mem_type'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_clock: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_clock = df_dropped.groupby(['vendor', \"brand\", 'clock'])['clock'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_clock.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_clock.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_clock'] = Fav\r\n",
    "bvs_cat['fav_clock'] = bvs_cat['fav_clock'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_continent: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_continent = df_dropped.groupby(['vendor', \"brand\", 'continent'])['continent'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_continent.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_continent.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_continent'] = Fav\r\n",
    "bvs_cat['fav_continent'] = bvs_cat['fav_continent'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_region: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_region = df_dropped.groupby(['vendor', \"brand\", 'region'])['region'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_region.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_region.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_region'] = Fav\r\n",
    "bvs_cat['fav_region'] = bvs_cat['fav_region'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_most: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_most = df_dropped.groupby(['vendor', \"brand\", 'conversion_rate'])['conversion_rate'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in Conv_most.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in Conv_most.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Conv_most'] = Fav\r\n",
    "bvs_cat['Conv_most'] = bvs_cat['Conv_most'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_less: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_less = df_dropped.groupby(['vendor', \"brand\", 'conversion_rate'])['conversion_rate'].count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in Conv_less.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in Conv_less.iteritems():\r\n",
    "            if tmp > y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Conv_less'] = Fav\r\n",
    "bvs_cat['Conv_less'] = bvs_cat['Conv_less'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_max: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_max = df_dropped.groupby(['vendor', \"brand\"])[\"conversion_rate\"].max()\r\n",
    "\r\n",
    "Conv_max = pd.DataFrame(Conv_max)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Conv_max'] = Conv_max\r\n",
    "bvs_cat['Conv_max'] = bvs_cat['Conv_max'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conv_min: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv_min = df_dropped.groupby(['vendor', \"brand\"])[\"conversion_rate\"].min()\r\n",
    "\r\n",
    "Conv_min = pd.DataFrame(Conv_min)\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['Conv_min'] = Conv_min\r\n",
    "bvs_cat['Conv_min'] = bvs_cat['Conv_min'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fav_week: month during which the customer tends to spend the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_week = df_dropped.copy()\r\n",
    "df_with_week['time_code'] = df_with_week.time_code.dt.week\r\n",
    "\r\n",
    "fav_week = df_with_week.groupby(['vendor', \"brand\", \"time_code\"]).time_code.count()\r\n",
    "\r\n",
    "Fav = {}\r\n",
    "for x in fav_week.iteritems():\r\n",
    "    if (x[0][0], x[0][1]) not in Fav:\r\n",
    "        tmp= x[1]\r\n",
    "        Fav[(x[0][0], x[0][1])] = x[0][2]\r\n",
    "        for y in fav_week.iteritems():\r\n",
    "            if tmp < y[1]:\r\n",
    "                if x[0][0] == y[0][0]:\r\n",
    "                    if x[0][1] == y[0][1]:\r\n",
    "                        tmp = y[1]\r\n",
    "                        Fav[(y[0][0], y[0][1])] = y[0][2] \r\n",
    "\r\n",
    "\r\n",
    "#print(Fav)\r\n",
    "\r\n",
    "# create dataframe\r\n",
    "Fav = pd.DataFrame.from_dict(Fav, orient='index')\r\n",
    "\r\n",
    "\r\n",
    "# add column to the new dataset\r\n",
    "bvs_cat['fav_week'] = Fav\r\n",
    "bvs_cat['fav_week'] = bvs_cat['fav_week'].fillna(0)\r\n",
    "\r\n",
    "print(bvs_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics on the Vendor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvs = bvs[(bvs.I != 0)]\r\n",
    "bvs_cat = bvs_cat[(bvs_cat.fav_continent != 0)]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats on new dataset XXX\r\n",
    "print(bvs.describe())\r\n",
    "print()\r\n",
    "print(bvs_cat.describe())\r\n",
    "print()\r\n",
    "\r\n",
    "print(bvs.info())\r\n",
    "print()\r\n",
    "print(bvs_cat.info())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data distribution\r\n",
    "mpl.rc('figure', max_open_warning = 0)\r\n",
    "sturge_number = math.trunc(np.log2(len(bvs)))\r\n",
    "for col in bvs:  \r\n",
    "    print(\"\\n\\nCONSIDERATIONS ABOUT THE ATTRIBUTE: \" + col)\r\n",
    "    bvs[col].hist(bins = sturge_number + 1)  #Sturges' rule\r\n",
    "    pl.suptitle(col)    \r\n",
    "    #plt.savefig(dir+'\\\\Histogram\\\\'+col+'-hist.jpg')\r\n",
    "    plt.xticks(rotation=45)\r\n",
    "    plt.figure(figsize = (10,8))\r\n",
    "    plt.show()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization on categorical\r\n",
    "for x in bvs_cat:  \r\n",
    "    plt.bar(bvs_cat[x].unique(),bvs_cat[x].value_counts())\r\n",
    "    plt.xticks(rotation=90, horizontalalignment=\"center\")\r\n",
    "    plt.title(\"Distribution of \" + x)\r\n",
    "    plt.xlabel(x)\r\n",
    "    plt.ylabel(\"Number of customers\")\r\n",
    "    plt.show()\r\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp3= bvs.copy()\r\n",
    "tmp4= bvs_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\r\n",
    "for col in bvs:  \r\n",
    "    fig, ax = plt.subplots()\r\n",
    "    ax.set_title('\\nOutliers of ' +col+ ' in the Dataset')\r\n",
    "    ax.boxplot(bvs[col])\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    print(\"---------------------------------------------------------------\")\r\n",
    "    \r\n",
    "def iqr_values(s):\r\n",
    "    q1 = s.quantile(q = 0.25)\r\n",
    "\r\n",
    "    q3 = s.quantile(q = 0.75)    \r\n",
    "\r\n",
    "    iqr = q3 - q1\r\n",
    "\r\n",
    "    iqr_left = q1 - 3*iqr\r\n",
    "    \r\n",
    "    iqr_right = q3 + 3*iqr\r\n",
    "    \r\n",
    "    return iqr_left, iqr_right\r\n",
    "\r\n",
    "\r\n",
    "for x in bvs:\r\n",
    "    if (x != \"Imin\") & (x != \"Type_unik\"):\r\n",
    "        print(\"OUTLIERS REPRESENTATION FOR ATTRIBUTE :\\t\" + x)\r\n",
    "        left_sale, right_sale = iqr_values(bvs[x])\r\n",
    "        print(left_sale)\r\n",
    "        print(right_sale)\r\n",
    "        bvs[(bvs[x] > left_sale) & (bvs[x] < right_sale)][x].plot.box()\r\n",
    "        plt.show()\r\n",
    "        print(bvs)\r\n",
    "        outliers = bvs[(bvs[x] < left_sale) | (bvs[x] > right_sale)]\r\n",
    "        print(\"\\n Outliers founded\")\r\n",
    "        print()\r\n",
    "        print(outliers.describe())\r\n",
    "        print()\r\n",
    "        outliers.drop_duplicates(inplace=True)\r\n",
    "        print(\"--------------------------------------------------\")\r\n",
    "        print(\"\\n Dataset dropped\")\r\n",
    "        #vs_dropped[x] = bvs[x][(bvs[x] > left_sale) & (bvs[x] < right_sale)]\r\n",
    "        bvs.drop(outliers.index, inplace=True, errors=\"ignore\")\r\n",
    "        bvs_cat.drop(outliers.index, inplace=True)\r\n",
    "        print(bvs.describe())\r\n",
    "        print()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCorrelation Matrix with Spearman::\")\r\n",
    "corr = bvs.corr(method='spearman')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "# correlation\r\n",
    "print(\"\\nCorrelation Matrix with Pearson::\")\r\n",
    "#plt.rc('figure', figsize=(18, 7))\r\n",
    "corr = bvs.corr(method='pearson')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "print(\"\\nHeatmap correlation::\")\r\n",
    "sns.heatmap(bvs.corr(), annot=True);\r\n",
    "\r\n",
    "\"\"\"for x in bvs:\r\n",
    "    for y in bvs:\r\n",
    "        if x != y:\r\n",
    "            plt.figure(figsize = (15,15))\r\n",
    "            plt.scatter(bvs[x], bvs[y])\r\n",
    "            plt.xlabel(x)\r\n",
    "            plt.ylabel(y)\r\n",
    "            plt.title('\\nCorrelation between ' + x + ' and ' + y + ' in vs')\r\n",
    "            plt.show()\"\"\"\r\n",
    "\r\n",
    "#---- maintain attributes below a certain threshold\r\n",
    "high_corr = []\r\n",
    "print(high_corr)\r\n",
    "threshold = 0.80\r\n",
    "list_corr = list(corr.to_numpy())\r\n",
    "ext_ind = 0\r\n",
    "for i in list_corr:\r\n",
    "    int_ind = 0\r\n",
    "    for j in i:\r\n",
    "        if j > threshold and int_ind != ext_ind:\r\n",
    "            high_corr.append(int_ind)\r\n",
    "        int_ind += 1\r\n",
    "    ext_ind += 1\r\n",
    "print(\"Attributes above threshold of \" + str(threshold) + \" are:\\n\")\r\n",
    "print(list(bvs.columns[high_corr]))\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bvs.drop(columns=list(bvs.columns[high_corr]), axis=1)\r\n",
    "\r\n",
    "# correlation\r\n",
    "print(\"\\nCorrelation Matrix with Pearson::\")\r\n",
    "corr = tmp.corr(method='pearson')\r\n",
    "sns.set(font_scale=0.8)\r\n",
    "#plt.figure(figsize = (7,7))\r\n",
    "ax = sns.heatmap(corr, vmin=-0.1, vmax=1, linewidths=1, annot=True)\r\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45,horizontalalignment='right')   #Look the method\r\n",
    "plt.rc('figure', figsize=(18, 7))\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bvs = tmp3.copy()\r\n",
    "#bvs_cat = tmp4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_num = vs.copy()\r\n",
    "vs_num.to_csv(path_or_buf=dir + '\\\\Data\\\\vs_num.csv')\r\n",
    "vs_cat.to_csv(path_or_buf=dir + '\\\\Data\\\\vs_cat.csv')\r\n",
    "\r\n",
    "bvs_num = tmp.copy()\r\n",
    "bvs_num.to_csv(path_or_buf=dir + '\\\\Data\\\\bvs_num.csv')\r\n",
    "bvs_cat.to_csv(path_or_buf=dir + '\\\\Data\\\\bvs_cat.csv')\r\n",
    "\r\n",
    "df_dropped.to_csv(path_or_buf=dir + '\\\\Data\\\\df_dropped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################# END ######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### FUTURE CONSIDERATIONS\n",
    "- RFM Analysis\n",
    "RFM (Recency, Frequency, Monetary) analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups. RFM helps divide customers into various categories or clusters to\n",
    "identify customers who are more likely to respond to promotions and also for future personalization services. Frequency is the number of orders for each customer; Recency is the number of days between present date and date of last purchase each customer; Monetary is the purchase price for each customer.\n",
    "\n",
    "\n",
    "- leave out extreme values from the sample (for instance, the 3% smallest and the 3% largest values) for calculating and displaying the histogram, or one can deviate from the principle of bins of equal length\n",
    "\n",
    "\n",
    "- Convert numerical values into standard units, especially if data from different sources (and different countries) are used.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe0fd05f9ecc1bba0c525d982046f76f8af1c67c8117e2e90af1b7cd44f1ddc6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}